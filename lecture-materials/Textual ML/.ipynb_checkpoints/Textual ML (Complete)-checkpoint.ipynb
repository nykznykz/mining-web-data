{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Reading in the Kaggle data and adding features\n",
    "2. Using a **`Pipeline`** for proper cross-validation\n",
    "3. Combining **`GridSearchCV`** with **`Pipeline`**\n",
    "4. Efficiently searching for tuning parameters using **`RandomizedSearchCV`**\n",
    "5. Adding features to a document-term matrix (using SciPy)\n",
    "6. Adding features to a document-term matrix (using **`FeatureUnion`**)\n",
    "7. Ensembling models\n",
    "8. Locating groups of similar cuisines\n",
    "9. Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Kaggle data and adding features\n",
    "\n",
    "- Our goal is to predict the **cuisine** of a recipe, given its **ingredients**.\n",
    "- **Feature engineering** is the process through which you create features that don't natively exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame and adds new features\n",
    "def make_features(df):\n",
    "    \n",
    "    # number of ingredients\n",
    "    df['num_ingredients'] = df.ingredients.apply(len)\n",
    "    \n",
    "    # mean length of ingredient names\n",
    "    df['ingredient_length'] = df.ingredients.apply(lambda x: np.mean([len(item) for item in x]))\n",
    "    \n",
    "    # string representation of the ingredient list\n",
    "    df['ingredients_str'] = df.ingredients.astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the same features in the training data and the new data\n",
    "train = make_features(pd.read_json('./data/train.json'))\n",
    "new = make_features(pd.read_json('./data/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>['baking powder', 'eggs', 'all-purpose flour',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>['sugar', 'egg yolks', 'corn starch', 'cream o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>['sausage links', 'fennel bulb', 'fronds', 'ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['meat cuts', 'file powder', 'smoked sausage',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>['ground black pepper', 'salt', 'sausage casin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \n",
       "0           9.333333  ['baking powder', 'eggs', 'all-purpose flour',...  \n",
       "1          10.272727  ['sugar', 'egg yolks', 'corn starch', 'cream o...  \n",
       "2           9.666667  ['sausage links', 'fennel bulb', 'fronds', 'ol...  \n",
       "3          12.000000  ['meat cuts', 'file powder', 'smoked sausage',...  \n",
       "4          13.000000  ['ground black pepper', 'salt', 'sausage casin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using a `Pipeline` for proper cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = train.ingredients_str\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is just a Series of strings\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace the regex pattern that is used for tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import and instantiate Multinomial Naive Bayes (with the default parameters)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a pipeline of vectorization and Naive Bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "          vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proper cross-validation:**\n",
    "\n",
    "- By passing our pipeline to **`cross_val_score`**, features will be created from **`X`** (via **`CountVectorizer`**) within each fold of cross-validation.\n",
    "- This process simulates the real world, in which your out-of-sample data will contain **features that were not seen** during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7322884933790151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining `GridSearchCV` with `Pipeline`\n",
    "\n",
    "- We use **`GridSearchCV`** to locate optimal tuning parameters by performing an \"exhaustive grid search\" of different parameter combinations, searching for the combination that has the best cross-validated accuracy.\n",
    "- By passing a **`Pipeline`** to **`GridSearchCV`** (instead of just a model), we can search tuning parameters for both the vectorizer and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['multinomialnb', 'countvectorizer'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pass the pipeline (instead of the model) to GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.8 s, sys: 759 ms, total: 35.6 s\n",
      "Wall time: 36.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'multinomialnb__alpha': [0.5, 1], 'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the grid search\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_search.py:667: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.72422, std: 0.00457, params: {'multinomialnb__alpha': 0.5, 'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b'},\n",
       " mean: 0.72351, std: 0.00469, params: {'multinomialnb__alpha': 1, 'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b'},\n",
       " mean: 0.74770, std: 0.00460, params: {'multinomialnb__alpha': 0.5, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"},\n",
       " mean: 0.73229, std: 0.00552, params: {'multinomialnb__alpha': 1, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the score for each combination of parameters\n",
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7476995021873586\n",
      "{'multinomialnb__alpha': 0.5, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Efficiently searching for tuning parameters using `RandomizedSearchCV`\n",
    "\n",
    "- When there are many parameters to tune, searching all possible combinations of parameter values may be **computationally infeasible**.\n",
    "- **`RandomizedSearchCV`** searches a sample of the parameter values, and you control the computational \"budget\".\n",
    "\n",
    "[RandomizedSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats documentation](http://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__min_df': [1, 2, 3],\n",
       " 'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen at 0x11e833be0>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for any continuous parameters, specify a distribution instead of a list of options\n",
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3]\n",
    "param_grid['multinomialnb__alpha'] = sp.stats.uniform(scale=1)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a random seed for sp.stats.uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# additional parameters are n_iter (number of searches) and random_state\n",
    "rand = RandomizedSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_iter=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 729 ms, total: 30.1 s\n",
      "Wall time: 32.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "          fit_params={}, iid=True, n_iter=5, n_jobs=1,\n",
       "          param_distributions={'countvectorizer__min_df': [1, 2, 3], 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x11e833be0>, 'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"]},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the randomized search\n",
    "%time rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.74986, std: 0.00494, params: {'countvectorizer__min_df': 2, 'multinomialnb__alpha': 0.417022004702574, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"},\n",
       " mean: 0.72434, std: 0.00444, params: {'countvectorizer__min_df': 1, 'multinomialnb__alpha': 0.7203244934421581, 'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b'},\n",
       " mean: 0.72829, std: 0.00537, params: {'countvectorizer__min_df': 2, 'multinomialnb__alpha': 0.00011437481734488664, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"},\n",
       " mean: 0.75137, std: 0.00438, params: {'countvectorizer__min_df': 2, 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"},\n",
       " mean: 0.72218, std: 0.00438, params: {'countvectorizer__min_df': 1, 'multinomialnb__alpha': 0.14675589081711304, 'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.751370241866546\n",
      "{'countvectorizer__min_df': 2, 'multinomialnb__alpha': 0.30233257263183977, 'countvectorizer__token_pattern': \"'([a-z ]+)'\"}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.30233257263183977, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['british', 'southern_us', 'italian', ..., 'italian', 'southern_us',\n",
       "       'mexican'], dtype='<U12')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV/GridSearchCV automatically refit the best model with the entire dataset, and can be used to make predictions\n",
    "new_pred_class_rand = rand.predict(X_new)\n",
    "new_pred_class_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75342)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class_rand}).set_index('id').to_csv('sub3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding features to a document-term matrix (using SciPy)\n",
    "\n",
    "- So far, we've trained models on either the **document-term matrix** or the **manually created features**, but not both.\n",
    "- To train a model on both types of features, we need to **combine them into a single feature matrix**.\n",
    "- Because one of the matrices is **sparse** and the other is **dense**, the easiest way to combine them is by using SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.sparse documentation](http://docs.scipy.org/doc/scipy/reference/sparse.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of the manually created features\n",
    "X_manual = train.loc[:, ['num_ingredients', 'ingredient_length']]\n",
    "X_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sparse matrix from the DataFrame\n",
    "X_manual_sparse = sp.sparse.csr_matrix(X_manual)\n",
    "type(X_manual_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two sparse matrices\n",
    "X_dtm_manual = sp.sparse.hstack([X_dtm, X_manual_sparse])\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This was a relatively easy process.\n",
    "- However, it does not allow us to do **proper cross-validation**, and it doesn't integrate well with the rest of the **scikit-learn workflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Adding features to a document-term matrix (using `FeatureUnion`)\n",
    "\n",
    "- Below is an alternative process that does allow for proper cross-validation, and does integrate well with the scikit-learn workflow.\n",
    "- To use this process, we have to learn about transformers, **`FunctionTransformer`**, and **`FeatureUnion`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are \"transformers\"?\n",
    "\n",
    "Transformer objects provide a `transform` method in order to perform **data transformations**. Here are a few examples:\n",
    "\n",
    "- **`CountVectorizer`**\n",
    "    - `fit` learns the vocabulary\n",
    "    - `transform` creates a document-term matrix using the vocabulary\n",
    "- **`Imputer`**\n",
    "    - `fit` learns the value to impute\n",
    "    - `transform` fills in missing entries using the imputation value\n",
    "- **`StandardScaler`**\n",
    "    - `fit` learns the mean and scale of each feature\n",
    "    - `transform` standardizes the features using the mean and scale\n",
    "- **`HashingVectorizer`**\n",
    "    - `fit` is not used, and thus it is known as a \"stateless\" transformer\n",
    "    - `transform` creates the document-term matrix using a hash of the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a function into a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the manually created features\n",
    "def get_manual(df):\n",
    "    return df.loc[:, ['num_ingredients', 'ingredient_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_manual(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FunctionTransformer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) (new in 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._function_transformer.FunctionTransformer"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a stateless transformer from the get_manual function\n",
    "get_manual_ft = FunctionTransformer(get_manual, validate=False)\n",
    "type(get_manual_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function using the transform method\n",
    "get_manual_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the ingredients string\n",
    "def get_text(df):\n",
    "    return df.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and test another transformer\n",
    "get_text_ft = FunctionTransformer(get_text, validate=False)\n",
    "get_text_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining feature extraction steps\n",
    "\n",
    "- **`FeatureUnion`** applies a list of transformers in parallel to the input data (not sequentially), then **concatenates the results**.\n",
    "- This is useful for combining several feature extraction mechanisms into a single transformer.\n",
    "\n",
    "![Pipeline versus FeatureUnion](pipeline_versus_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_union documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is identical to a FeatureUnion with just one transformer\n",
    "union = make_union(vect)\n",
    "X_dtm = union.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to add a second transformer to the Feature Union (what's wrong with this?)\n",
    "# union = make_union(vect, get_manual_ft)\n",
    "# X_dtm_manual = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly combine the transformers into a FeatureUnion\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "X_dtm_manual = union.fit_transform(train)\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline in a FeatureUnion](pipeline_in_a_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102895106852953"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly improper cross-validation\n",
    "cross_val_score(nb, X_dtm_manual, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a pipeline of the FeatureUnion and Naive Bayes\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134318388611878"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly cross-validate the entire pipeline (and pass it the entire DataFrame)\n",
    "cross_val_score(pipe, train, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to specify `Pipeline` and `FeatureUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reminder of how we created the pipeline\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [FeatureUnion documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# duplicate the pipeline structure without using make_pipeline or make_union\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "pipe = Pipeline([\n",
    "    ('featureunion', FeatureUnion([\n",
    "            ('pipeline', Pipeline([\n",
    "                    ('functiontransformer', get_text_ft),\n",
    "                    ('countvectorizer', vect)\n",
    "                    ])),\n",
    "            ('functiontransformer', get_manual_ft)\n",
    "        ])),\n",
    "    ('multinomialnb', nb)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search of a nested `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('featureunion', FeatureUnion(n_jobs=1,\n",
       "         transformer_list=[('pipeline', Pipeline(steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "            func=<function get_text at 0x1167b79d8>, inv_kw_args=None,\n",
       "            inverse_func=None, kw_args=None, pass_y=False, validate=False)), ('countvectorizer', CountVectorizer(analyzer...b7048>, inv_kw_args=None,\n",
       "            inverse_func=None, kw_args=None, pass_y=False, validate=False))],\n",
       "         transformer_weights=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "  \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['featureunion__pipeline__countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.9 s, sys: 1.75 s, total: 41.7 s\n",
      "Wall time: 43.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(steps=[('featureunion', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('pipeline', Pipeline(steps=[('functiontransformer', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_text at 0x1167b79d8>, inv_kw_args=None,\n",
       "          inverse_func=None, kw_args=None, pass_y=False, validate...ormer_weights=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'multinomialnb__alpha': [0.5, 1], 'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426710916679238\n",
      "{'multinomialnb__alpha': 0.5, 'featureunion__pipeline__countvectorizer__token_pattern': \"'([a-z ]+)'\"}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Ensembling models\n",
    "\n",
    "Rather than combining features into a single feature matrix and training a single model, we can instead create separate models and \"ensemble\" them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is ensembling?\n",
    "\n",
    "Ensemble learning (or \"ensembling\") is the process of combining several predictive models in order to produce a combined model that is **better than any individual model**.\n",
    "\n",
    "- **Regression:** average the predictions made by the individual models\n",
    "- **Classification:** let the models \"vote\" and use the most common prediction, or average the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different \"processes\", such as:\n",
    "    - different types of models\n",
    "    - different features\n",
    "    - different tuning parameters\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "**Note:** There are also models that have built-in ensembling, such as Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: KNN model using only manually created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['num_ingredients', 'ingredient_length']\n",
    "X = train[feature_cols]\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use KNN with K=800\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=800, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train KNN on all of the training data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the manually created features\n",
    "X_new = new[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_knn = knn.predict_proba(X_new)\n",
    "new_pred_prob_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02625, 0.0275 , 0.01375, 0.04375, 0.03375, 0.08   , 0.0175 ,\n",
       "       0.075  , 0.0275 , 0.135  , 0.01   , 0.075  , 0.01875, 0.165  ,\n",
       "       0.00875, 0.0125 , 0.1525 , 0.025  , 0.0275 , 0.025  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_knn[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x116758188>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display classes with probabilities\n",
    "zip(knn.classes_, new_pred_prob_knn[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilities will sum to 1 for each row\n",
    "new_pred_prob_knn[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Naive Bayes model using only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "        vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=0.30233257263183977, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_rand = rand.predict_proba(X_new)\n",
    "new_pred_prob_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.35624509e-04, 5.10677208e-01, 5.01039760e-05, 7.46758455e-05,\n",
       "       3.64528916e-03, 1.36909784e-03, 4.25463842e-04, 3.16817133e-04,\n",
       "       1.85847350e-01, 3.78331630e-03, 2.67495007e-04, 5.60369424e-04,\n",
       "       4.27190054e-06, 8.85175984e-04, 8.50499605e-06, 3.04368393e-02,\n",
       "       2.60701445e-01, 3.09630257e-04, 1.07646647e-06, 2.45297976e-07])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_rand[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling models 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01344281, 0.2690886 , 0.00690005, 0.02191234, 0.01869764,\n",
       "       0.04068455, 0.00896273, 0.03765841, 0.10667368, 0.06939166,\n",
       "       0.00513375, 0.03778018, 0.00937714, 0.08294259, 0.00437925,\n",
       "       0.02146842, 0.20660072, 0.01265482, 0.01375054, 0.01250012])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for the first row\n",
    "(new_pred_prob_knn[0, :] + new_pred_prob_rand[0, :]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013443</td>\n",
       "      <td>0.269089</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.021912</td>\n",
       "      <td>0.018698</td>\n",
       "      <td>0.040685</td>\n",
       "      <td>0.008963</td>\n",
       "      <td>0.037658</td>\n",
       "      <td>0.106674</td>\n",
       "      <td>0.069392</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.037780</td>\n",
       "      <td>0.009377</td>\n",
       "      <td>0.082943</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>0.206601</td>\n",
       "      <td>0.012655</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>0.023884</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.010629</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.027501</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.547901</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.013125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.015010</td>\n",
       "      <td>0.041365</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.408696</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>0.038752</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.080630</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>0.008240</td>\n",
       "      <td>0.079377</td>\n",
       "      <td>0.158440</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.012502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.038750</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.020097</td>\n",
       "      <td>0.021250</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.044922</td>\n",
       "      <td>0.017501</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.640841</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.083129</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.072838</td>\n",
       "      <td>0.018252</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brazilian   british  cajun_creole   chinese  filipino    french     greek  \\\n",
       "0   0.013443  0.269089      0.006900  0.021912  0.018698  0.040685  0.008963   \n",
       "1   0.008752  0.011324      0.016875  0.045000  0.018132  0.023884  0.015625   \n",
       "2   0.013158  0.009389      0.006951  0.020000  0.015010  0.041365  0.010101   \n",
       "3   0.003125  0.004375      0.533750  0.038750  0.001875  0.023125  0.006250   \n",
       "4   0.001878  0.009856      0.020097  0.021250  0.003125  0.044922  0.017501   \n",
       "\n",
       "     indian     irish   italian  jamaican  japanese    korean   mexican  \\\n",
       "0  0.037658  0.106674  0.069392  0.005134  0.037780  0.009377  0.082943   \n",
       "1  0.046250  0.010629  0.070625  0.005626  0.027501  0.021875  0.066875   \n",
       "2  0.029376  0.013372  0.408696  0.005628  0.038752  0.007500  0.080630   \n",
       "3  0.075625  0.001250  0.051875  0.011875  0.008125  0.003125  0.107500   \n",
       "4  0.013750  0.012547  0.640841  0.003752  0.007500  0.003750  0.083129   \n",
       "\n",
       "   moroccan   russian  southern_us   spanish      thai  vietnamese  \n",
       "0  0.004379  0.021468     0.206601  0.012655  0.013751    0.012500  \n",
       "1  0.008125  0.008750     0.547901  0.007500  0.025625    0.013125  \n",
       "2  0.025887  0.008240     0.079377  0.158440  0.015625    0.012502  \n",
       "3  0.029375  0.001875     0.025000  0.007500  0.038125    0.027500  \n",
       "4  0.004376  0.003135     0.072838  0.018252  0.014375    0.003125  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for all rows\n",
    "new_pred_prob = pd.DataFrame((new_pred_prob_knn + new_pred_prob_rand) / 2, columns=knn.classes_)\n",
    "new_pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         british\n",
       "1     southern_us\n",
       "2         italian\n",
       "3    cajun_creole\n",
       "4         italian\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row, find the column with the highest predicted probability\n",
    "new_pred_class = new_pred_prob.apply(np.argmax, axis=1)\n",
    "new_pred_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75241)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class}).set_index('id').to_csv('sub4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** [VotingClassifier](http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier) (new in 0.17) makes it easier to ensemble classifiers, though it is limited to the case in which all of the classifiers are fit to the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Locating groups of similar cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "brazilian       ['ice cubes', 'club soda', 'white rum', 'lime'...\n",
       "british         ['greek yogurt', 'lemon curd', 'confectioners ...\n",
       "cajun_creole    ['herbs', 'lemon juice', 'fresh tomatoes', 'pa...\n",
       "chinese         ['low sodium soy sauce', 'fresh ginger', 'dry ...\n",
       "filipino        ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "french          ['sugar', 'salt', 'fennel bulb', 'water', 'lem...\n",
       "greek           ['romaine lettuce', 'black olives', 'grape tom...\n",
       "indian          ['water', 'vegetable oil', 'wheat', 'salt']['b...\n",
       "irish           ['cooking spray', 'salt', 'black pepper', 'yuk...\n",
       "italian         ['sugar', 'pistachio nuts', 'white almond bark...\n",
       "jamaican        ['plain flour', 'sugar', 'butter', 'eggs', 'fr...\n",
       "japanese        ['sirloin', 'mirin', 'yellow onion', 'low sodi...\n",
       "korean          ['jasmine rice', 'garlic', 'scallions', 'sugar...\n",
       "mexican         ['olive oil', 'purple onion', 'fresh pineapple...\n",
       "moroccan        ['ground cloves', 'whole nutmegs', 'ground gin...\n",
       "russian         ['water', 'grits', 'mozzarella cheese', 'salt'...\n",
       "southern_us     ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "spanish         ['olive oil', 'salt', 'medium shrimp', 'pepper...\n",
       "thai            ['sugar', 'hot chili', 'asian fish sauce', 'li...\n",
       "vietnamese      ['soy sauce', 'vegetable oil', 'red bell peppe...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each cuisine, combine all of the recipes into a single string\n",
    "cuisine_ingredients = train.groupby('cuisine').ingredients_str.sum()\n",
    "cuisine_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['ice cubes', 'club soda', 'white rum', 'lime', 'turbinado']['eggs', 'hearts of palm', 'cilantro', 'coconut cream', 'flax seed meal', 'kosher salt', 'jalapeno chilies', 'garlic', 'cream cheese, soften', 'coconut oil', 'lime juice', 'crushed red pepper flakes', 'ground coriander', 'pepper', 'chicken breasts', 'coconut flour', 'onions']['sweetened condensed milk', 'butter', 'cocoa powder']['lime', 'crushed ice', 'simple syrup', 'cachaca']['sugar', 'corn starch', 'egg whites', 'boiling water', 'col\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the brazilian ingredients\n",
    "cuisine_ingredients['brazilian'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     ['ice cubes', 'club soda', 'white rum', 'lime'...\n",
       "380    ['eggs', 'hearts of palm', 'cilantro', 'coconu...\n",
       "423    ['sweetened condensed milk', 'butter', 'cocoa ...\n",
       "509    ['lime', 'crushed ice', 'simple syrup', 'cacha...\n",
       "724    ['sugar', 'corn starch', 'egg whites', 'boilin...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that they match the brazilian recipes\n",
    "train.loc[train.cuisine=='brazilian', 'ingredients_str'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 3010)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from cuisine_ingredients\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "cuisine_dtm = vect.fit_transform(cuisine_ingredients)\n",
    "cuisine_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to calculate document similarity](http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity/12128777#12128777) (Stack Overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between each cuisine and all other cuisines\n",
    "from sklearn import metrics\n",
    "cuisine_similarity = []\n",
    "for idx in range(cuisine_dtm.shape[0]):\n",
    "    similarity = metrics.pairwise.linear_kernel(cuisine_dtm[idx, :], cuisine_dtm).flatten()\n",
    "    cuisine_similarity.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cuisine</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.742324</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.687271</td>\n",
       "      <td>0.665713</td>\n",
       "      <td>0.740527</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.571440</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.743156</td>\n",
       "      <td>0.807694</td>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.653801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.660232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591230</td>\n",
       "      <td>0.467640</td>\n",
       "      <td>0.631356</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.562750</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.926682</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.662057</td>\n",
       "      <td>0.508296</td>\n",
       "      <td>0.447177</td>\n",
       "      <td>0.560446</td>\n",
       "      <td>0.543260</td>\n",
       "      <td>0.909551</td>\n",
       "      <td>0.911271</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.478901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.742324</td>\n",
       "      <td>0.591230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.746151</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.688391</td>\n",
       "      <td>0.618955</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.578645</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.649831</td>\n",
       "      <td>0.657802</td>\n",
       "      <td>0.747480</td>\n",
       "      <td>0.803637</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.605224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.467640</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839803</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>0.460746</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.561837</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.817005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.631356</td>\n",
       "      <td>0.746151</td>\n",
       "      <td>0.839803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682939</td>\n",
       "      <td>0.607436</td>\n",
       "      <td>0.655934</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.670628</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.748558</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.678302</td>\n",
       "      <td>0.614984</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.720368</td>\n",
       "      <td>0.727409</td>\n",
       "      <td>0.741512</td>\n",
       "      <td>0.806833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.682939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759936</td>\n",
       "      <td>0.624868</td>\n",
       "      <td>0.837384</td>\n",
       "      <td>0.835272</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.540279</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>0.666830</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.881173</td>\n",
       "      <td>0.862062</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.548375</td>\n",
       "      <td>0.570925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.562750</td>\n",
       "      <td>0.688391</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.607436</td>\n",
       "      <td>0.759936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.859270</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.469465</td>\n",
       "      <td>0.479835</td>\n",
       "      <td>0.696644</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.649530</td>\n",
       "      <td>0.641229</td>\n",
       "      <td>0.837448</td>\n",
       "      <td>0.519004</td>\n",
       "      <td>0.538683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.687271</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.618955</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>0.655934</td>\n",
       "      <td>0.624868</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577338</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.734926</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.708621</td>\n",
       "      <td>0.795271</td>\n",
       "      <td>0.607432</td>\n",
       "      <td>0.617278</td>\n",
       "      <td>0.678865</td>\n",
       "      <td>0.627460</td>\n",
       "      <td>0.605162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.665713</td>\n",
       "      <td>0.926682</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.460746</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.837384</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.577338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649878</td>\n",
       "      <td>0.680914</td>\n",
       "      <td>0.494762</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>0.563303</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.902850</td>\n",
       "      <td>0.630921</td>\n",
       "      <td>0.449931</td>\n",
       "      <td>0.481712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.740527</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.670628</td>\n",
       "      <td>0.835272</td>\n",
       "      <td>0.859270</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.649878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695768</td>\n",
       "      <td>0.510280</td>\n",
       "      <td>0.522568</td>\n",
       "      <td>0.733959</td>\n",
       "      <td>0.709827</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.718945</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>0.555088</td>\n",
       "      <td>0.571096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.662057</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.734926</td>\n",
       "      <td>0.680914</td>\n",
       "      <td>0.695768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584689</td>\n",
       "      <td>0.609203</td>\n",
       "      <td>0.731859</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.752862</td>\n",
       "      <td>0.751672</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.664175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.508296</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.748558</td>\n",
       "      <td>0.540279</td>\n",
       "      <td>0.469465</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.494762</td>\n",
       "      <td>0.510280</td>\n",
       "      <td>0.584689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819828</td>\n",
       "      <td>0.506539</td>\n",
       "      <td>0.477401</td>\n",
       "      <td>0.557275</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.547336</td>\n",
       "      <td>0.682604</td>\n",
       "      <td>0.738413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.571440</td>\n",
       "      <td>0.447177</td>\n",
       "      <td>0.578645</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>0.479835</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.522568</td>\n",
       "      <td>0.609203</td>\n",
       "      <td>0.819828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516461</td>\n",
       "      <td>0.477964</td>\n",
       "      <td>0.517680</td>\n",
       "      <td>0.516811</td>\n",
       "      <td>0.582969</td>\n",
       "      <td>0.671054</td>\n",
       "      <td>0.747119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>0.743736</td>\n",
       "      <td>0.560446</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.561837</td>\n",
       "      <td>0.678302</td>\n",
       "      <td>0.666830</td>\n",
       "      <td>0.696644</td>\n",
       "      <td>0.708621</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>0.733959</td>\n",
       "      <td>0.731859</td>\n",
       "      <td>0.506539</td>\n",
       "      <td>0.516461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>0.630541</td>\n",
       "      <td>0.691398</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.623531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.543260</td>\n",
       "      <td>0.649831</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.614984</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.795271</td>\n",
       "      <td>0.563303</td>\n",
       "      <td>0.709827</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.477401</td>\n",
       "      <td>0.477964</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608343</td>\n",
       "      <td>0.605958</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.553375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.909551</td>\n",
       "      <td>0.657802</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.881173</td>\n",
       "      <td>0.649530</td>\n",
       "      <td>0.607432</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.557275</td>\n",
       "      <td>0.517680</td>\n",
       "      <td>0.630541</td>\n",
       "      <td>0.608343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877901</td>\n",
       "      <td>0.702752</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>0.743156</td>\n",
       "      <td>0.911271</td>\n",
       "      <td>0.747480</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.720368</td>\n",
       "      <td>0.862062</td>\n",
       "      <td>0.641229</td>\n",
       "      <td>0.617278</td>\n",
       "      <td>0.902850</td>\n",
       "      <td>0.718945</td>\n",
       "      <td>0.752862</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.516811</td>\n",
       "      <td>0.691398</td>\n",
       "      <td>0.605958</td>\n",
       "      <td>0.877901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707774</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.562359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>0.807694</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.803637</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.727409</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.837448</td>\n",
       "      <td>0.678865</td>\n",
       "      <td>0.630921</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>0.751672</td>\n",
       "      <td>0.547336</td>\n",
       "      <td>0.582969</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.702752</td>\n",
       "      <td>0.707774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.741512</td>\n",
       "      <td>0.548375</td>\n",
       "      <td>0.519004</td>\n",
       "      <td>0.627460</td>\n",
       "      <td>0.449931</td>\n",
       "      <td>0.555088</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.682604</td>\n",
       "      <td>0.671054</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>0.653801</td>\n",
       "      <td>0.478901</td>\n",
       "      <td>0.605224</td>\n",
       "      <td>0.817005</td>\n",
       "      <td>0.806833</td>\n",
       "      <td>0.570925</td>\n",
       "      <td>0.538683</td>\n",
       "      <td>0.605162</td>\n",
       "      <td>0.481712</td>\n",
       "      <td>0.571096</td>\n",
       "      <td>0.664175</td>\n",
       "      <td>0.738413</td>\n",
       "      <td>0.747119</td>\n",
       "      <td>0.623531</td>\n",
       "      <td>0.553375</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.562359</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cuisine       brazilian   british  cajun_creole   chinese  filipino    french  \\\n",
       "cuisine                                                                         \n",
       "brazilian      1.000000  0.660232      0.742324  0.580756  0.769216  0.756392   \n",
       "british        0.660232  1.000000      0.591230  0.467640  0.631356  0.859609   \n",
       "cajun_creole   0.742324  0.591230      1.000000  0.605581  0.746151  0.708849   \n",
       "chinese        0.580756  0.467640      0.605581  1.000000  0.839803  0.540446   \n",
       "filipino       0.769216  0.631356      0.746151  0.839803  1.000000  0.682939   \n",
       "french         0.756392  0.859609      0.708849  0.540446  0.682939  1.000000   \n",
       "greek          0.695692  0.562750      0.688391  0.496090  0.607436  0.759936   \n",
       "indian         0.687271  0.560349      0.618955  0.553532  0.655934  0.624868   \n",
       "irish          0.665713  0.926682      0.635197  0.460746  0.641010  0.837384   \n",
       "italian        0.740527  0.632618      0.738159  0.555504  0.670628  0.835272   \n",
       "jamaican       0.778320  0.662057      0.780897  0.635953  0.792723  0.723225   \n",
       "japanese       0.555601  0.508296      0.532394  0.835587  0.748558  0.540279   \n",
       "korean         0.571440  0.447177      0.578645  0.866828  0.782623  0.502205   \n",
       "mexican        0.743736  0.560446      0.724877  0.561837  0.678302  0.666830   \n",
       "moroccan       0.669009  0.543260      0.649831  0.505655  0.614984  0.685384   \n",
       "russian        0.706087  0.909551      0.657802  0.521844  0.697000  0.881173   \n",
       "southern_us    0.743156  0.911271      0.747480  0.558514  0.720368  0.862062   \n",
       "spanish        0.807694  0.604000      0.803637  0.603526  0.727409  0.817541   \n",
       "thai           0.685539  0.445518      0.590103  0.755813  0.741512  0.548375   \n",
       "vietnamese     0.653801  0.478901      0.605224  0.817005  0.806833  0.570925   \n",
       "\n",
       "cuisine          greek    indian     irish   italian  jamaican  japanese  \\\n",
       "cuisine                                                                    \n",
       "brazilian     0.695692  0.687271  0.665713  0.740527  0.778320  0.555601   \n",
       "british       0.562750  0.560349  0.926682  0.632618  0.662057  0.508296   \n",
       "cajun_creole  0.688391  0.618955  0.635197  0.738159  0.780897  0.532394   \n",
       "chinese       0.496090  0.553532  0.460746  0.555504  0.635953  0.835587   \n",
       "filipino      0.607436  0.655934  0.641010  0.670628  0.792723  0.748558   \n",
       "french        0.759936  0.624868  0.837384  0.835272  0.723225  0.540279   \n",
       "greek         1.000000  0.640297  0.583675  0.859270  0.681281  0.469465   \n",
       "indian        0.640297  1.000000  0.577338  0.616211  0.734926  0.567993   \n",
       "irish         0.583675  0.577338  1.000000  0.649878  0.680914  0.494762   \n",
       "italian       0.859270  0.616211  0.649878  1.000000  0.695768  0.510280   \n",
       "jamaican      0.681281  0.734926  0.680914  0.695768  1.000000  0.584689   \n",
       "japanese      0.469465  0.567993  0.494762  0.510280  0.584689  1.000000   \n",
       "korean        0.479835  0.538853  0.458798  0.522568  0.609203  0.819828   \n",
       "mexican       0.696644  0.708621  0.591718  0.733959  0.731859  0.506539   \n",
       "moroccan      0.769412  0.795271  0.563303  0.709827  0.757462  0.477401   \n",
       "russian       0.649530  0.607432  0.892428  0.697593  0.684492  0.557275   \n",
       "southern_us   0.641229  0.617278  0.902850  0.718945  0.752862  0.554022   \n",
       "spanish       0.837448  0.678865  0.630921  0.858166  0.751672  0.547336   \n",
       "thai          0.519004  0.627460  0.449931  0.555088  0.650898  0.682604   \n",
       "vietnamese    0.538683  0.605162  0.481712  0.571096  0.664175  0.738413   \n",
       "\n",
       "cuisine         korean   mexican  moroccan   russian  southern_us   spanish  \\\n",
       "cuisine                                                                       \n",
       "brazilian     0.571440  0.743736  0.669009  0.706087     0.743156  0.807694   \n",
       "british       0.447177  0.560446  0.543260  0.909551     0.911271  0.604000   \n",
       "cajun_creole  0.578645  0.724877  0.649831  0.657802     0.747480  0.803637   \n",
       "chinese       0.866828  0.561837  0.505655  0.521844     0.558514  0.603526   \n",
       "filipino      0.782623  0.678302  0.614984  0.697000     0.720368  0.727409   \n",
       "french        0.502205  0.666830  0.685384  0.881173     0.862062  0.817541   \n",
       "greek         0.479835  0.696644  0.769412  0.649530     0.641229  0.837448   \n",
       "indian        0.538853  0.708621  0.795271  0.607432     0.617278  0.678865   \n",
       "irish         0.458798  0.591718  0.563303  0.892428     0.902850  0.630921   \n",
       "italian       0.522568  0.733959  0.709827  0.697593     0.718945  0.858166   \n",
       "jamaican      0.609203  0.731859  0.757462  0.684492     0.752862  0.751672   \n",
       "japanese      0.819828  0.506539  0.477401  0.557275     0.554022  0.547336   \n",
       "korean        1.000000  0.516461  0.477964  0.517680     0.516811  0.582969   \n",
       "mexican       0.516461  1.000000  0.697442  0.630541     0.691398  0.739874   \n",
       "moroccan      0.477964  0.697442  1.000000  0.608343     0.605958  0.784612   \n",
       "russian       0.517680  0.630541  0.608343  1.000000     0.877901  0.702752   \n",
       "southern_us   0.516811  0.691398  0.605958  0.877901     1.000000  0.707774   \n",
       "spanish       0.582969  0.739874  0.784612  0.702752     0.707774  1.000000   \n",
       "thai          0.671054  0.617627  0.533128  0.494331     0.536965  0.606200   \n",
       "vietnamese    0.747119  0.623531  0.553375  0.539100     0.562359  0.614200   \n",
       "\n",
       "cuisine           thai  vietnamese  \n",
       "cuisine                             \n",
       "brazilian     0.685539    0.653801  \n",
       "british       0.445518    0.478901  \n",
       "cajun_creole  0.590103    0.605224  \n",
       "chinese       0.755813    0.817005  \n",
       "filipino      0.741512    0.806833  \n",
       "french        0.548375    0.570925  \n",
       "greek         0.519004    0.538683  \n",
       "indian        0.627460    0.605162  \n",
       "irish         0.449931    0.481712  \n",
       "italian       0.555088    0.571096  \n",
       "jamaican      0.650898    0.664175  \n",
       "japanese      0.682604    0.738413  \n",
       "korean        0.671054    0.747119  \n",
       "mexican       0.617627    0.623531  \n",
       "moroccan      0.533128    0.553375  \n",
       "russian       0.494331    0.539100  \n",
       "southern_us   0.536965    0.562359  \n",
       "spanish       0.606200    0.614200  \n",
       "thai          1.000000    0.914986  \n",
       "vietnamese    0.914986    1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the results to a DataFrame\n",
    "cuisine_list = cuisine_ingredients.index\n",
    "cuisine_similarity = pd.DataFrame(cuisine_similarity, index=cuisine_list, columns=cuisine_list)\n",
    "cuisine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11ef3d320>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAE/CAYAAAAABhfPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXe8XEX5/9+fNFJJpNcQhACGFiAJVQgIiEoRRZpI/RFQ\nafoFVEQJTaoogoqhRSAiRdRQJGAg9JKQTkgAIUgIxVBCQki79/n9MbPJyWbbObfs3s3zvq/z2rPn\nzDMz5+zefc7MPPMZmRmO4ziO09q0q3YFHMdxnFUTd0CO4zhOVXAH5DiO41QFd0CO4zhOVXAH5DiO\n41QFd0CO4zhOVXAH5DiO45RF0i2SPpA0tch5SfqdpNclTZa0Y7k83QE5juM4lTAcOKDE+a8BfeM2\nBPhjuQzdATmO4zhlMbMngY9KJDkEuM0CzwO9JK1fKs8OzVlBpzRL5ryRWnbitv6/TF3O7l1LfUeK\nc9niLqltfrX+x5nKWrygfWqbGe+tmdpmkbI9Y33cPr3dzhnv+xobLkhtc9Ib3VLb9FDH1DYAF6y2\nOLXNuPlrZCpro4ZFqW3W6/lZepuBC1PbAIwZvV5qm/c6ZvsOnvr2HcpkmCDNb06ntTc7hdByyTHM\nzIalKG5D4O3E+1nx2LvFDNwBOY7jOERnk8bhNBl3QI7jOPVKY0NrlvYOsHHi/UbxWFHazBiQpD7F\noi+akOfBkn4a94dKOjvuXyRp3+Ysy3Ecp9VpWFr51nRGAsfGaLhdgLlmVrT7DeqsBSSpvZlV7PLN\nbCThpuUfTz/w4jiOU2OYNTZbXpLuBAYDa0maBVwAdAzl2A3AQ8DXgdeBBcAJ5fJsaw6og6QRwI7A\ny8CxwDTgLmA/4EpJPQgDaZ0IN+J7ZrZA0sREPlsSwgk3BQaY2WnJQiQNBx4ws3sl/RI4COgCPAuc\nYmYmaQzwArA30As4ycyeapnLdhzHyUBj8zkgMzuqzHkDfpgmzzbTBRfZEviDmX0J+BT4QTz+oZnt\naGZ/Be4zs4Fmtj3wCnASgJn1N7P+wC+AcQRnUgnXx/y2ITihAxPnOpjZIOAswtPASkgaImmcpHE3\n3XZnuqt1HMdpCtZY+VYF2loL6G0zeybu3wGcEffvSqTZRtIlhFZJd2BU7oSkvsBVwN5mtkSqKMpx\nb0nnAl2BNQgtr/vjufvi60tAn0LGyciSLGHYjuM4mWndIITUtDUHlP8DnnufnAgwHPimmU2SdDyh\nzxJJ3YG7gZPLDYzlkNQZ+AOhm+5tSUOBzokkuUkLDbS9e+k4Tr1TpZZNpbS1LrjeknaN+0cDTxdI\n0wN4V1JH4LuJ47cAt6Ycp8k5mznRgR2WtsKO4zjVwhqWVrxVg7bmgGYAP5T0CvAFCmsN/YIQHPAM\nMB1A0iYE53GipIlxG1CuMDP7BLgRmEroyhvbLFfhOI7TGjQ2Vr5VAYXABac1uHmjY1Lf7GMnXpS6\nnNMG/CS1DcDdcyaktjl7zZ0zlXXWqel7LL93Q3rZn6zf77/c9LXUNr89udK4lhVZJ0M3/TVLXktt\nM+PjWekLAg5ar6yo8UrMs/TyPQD3X7tXeqMMckvn/Whi+UQFuG52+kDXtbqunqms9z55pclSPIte\nfbrif4DVttijyeWlxcctHMdx6hUPQnAcx3GqggchtD6VyvYkJXcknSWpa+LcQ5J6lbCdKWmt5qmx\n4zhOC9C6UjypWWVbQFG2Jym5cxZhbtECADP7elUq5jiO01xUKbigUuqyBRTpIGmEpFck3Supa2y1\nXCFpPPAdScMlHSbpDGAD4HFJj8PyFo6kbpIelDRJ0lRJRyTKOF3SeElTJG1VjYt0HMcphllDxVs1\nqGcHVIlsDwBm9jtgNkEhYe+8fA4AZpvZ9lGO5+HEuTlmtiMhHPzsQpVISvE88Vn6yCXHcZzM1LgU\nTz07oHzZnj3i/l1F0hdjCrBfbDl92czmJs5VJMVjZgPMbMBe3fqmLNpxHKcJ1Pg8oHp2QJXI9pTP\nxOxVgvr2FOCSqI6dw6V4HMepXbwFVDUqke1JMo8g47MCkjYAFpjZHQQh0/Sz8hzHcapBw5LKtypQ\nzw6oEtmeJMOAh3NBCAm2BV6M6wldAFzS7DV1HMdpCWq8C86leFqR6Vt8PfXN/s3ibqnLuX7cFalt\nAM4dcF5qm1M7zy2fqADvf9I9tc3cDL2cL3TOpi7S3dI/mx3cIb1UEMCaveentjns1fT3ok+Hnqlt\nAM5sSP/j9LzSf74Aq2X4Odqrx5zUNutst6h8ogKc80L6qX/daZ+prN/M/GuTpXEWPndnxXe0865H\nuRSP4ziO00zU+Dwgd0CO4zj1ijug8kg6GOhnZpdXuy7lkDTfzLL1LziO47QiVqXggkqpCQdkZiOB\nka1ZpqQOZlYdASTHcZzWYFUWI5V0rKTJUcbmdkkHSXpB0gRJ/5a0bkx3vKTr4/5wSYcl8pgfXwdL\nGhNldaZHmZ2ig2aSBkp6Npb9oqQesZyRkh4DRsd050gaG+t5YcL+x1F6Z6qks4qUUdDWcRynJqjx\nKLgWawFJ2ho4H9jNzOZIWoMwGXQXMzNJ/w84F/i/FNnuAGxNkM15BtidAvN7JHUiKB4cYWZjJa0O\nfB5P7whsZ2YfSdof6AsMAgSMlLQnYbLqCcDO8fgLkp4wswmJMgramtmTeXUZAgwBuHCdrTm8Z+8U\nl+s4jtMEarwF1JJdcPsA95jZHID4g78tcJek9YFOwJsp83zRzGYBxHk5fSg8wXRL4F0zGxvL/jTa\nADxqZh/FdPvHLedYuhOcSnfg72b2WbS7D/hyIl0p2xUckJkNI8wxyhSG7TiOkxkPQliB64BrzGyk\npMHA0AJplhK7BiW1IziqHMng/azyN0kpHgGXmdmfkgkknVlBPgVtHcdxaoYabwG15BjQY4QlD9YE\niF1wPYF34vnjitjNBHaK+wcDHTOUPQNYX9LAWHYPSYWc1SjgRCnMmpO0oaR1gKeAb8YlHLoBh8Zj\nldg6juPUBkuXVr5VgRZrAZnZy5IuBZ6Q1EDoqhoK3CPpY4KD2jRpEl9vBP4paRJh6YNU4qGx7MVx\n3Z7rJHUhjP/sWyDdI5K+BDwXu+fmA8eY2XhJw4EXY9KbkuM/pWyBD4rV67LFXdJeCiPnTCifKI+7\n++zP8WsNSG135bhfpbZZdFXBVSjKcuqIT1Lb/Hfhh+kLmg9bdl0vtdmTc15JbfP0Wv1S2wDs8cbG\nqW3+ddS8DCU10G69tVNbffd376e2mb7w1dQ2AN07dE5t88Bnq6cv6LkO9GmXfjbFeT3TfwfXTP+v\n2HzUeAuoRbvgzOzPwJ/zDv+zQNI1gY+izfvALolzP4nHxwBjEnmfVqbssXn5AAyPWzLdtcC1Beyv\nAa4pcLx7Yr+gbbXJ4nzqlSzOp17J4nzqlSzOp03iY0ClkXQqcDzwrSpXxXEcp76o8RZQ1dWwzewG\nM9vWzDItFyrp75Imxu0jSW9K+mpemg0k3ds8NXYcx2kj1Pg8oKo7oKZiZoeaWX8z609QUzjHzEbl\npZltZocVzsFxHKdOacYF6SQdIGmGpNcl/bTA+S/EBsHkOPl/m3J5tmkHlK+0EA/vGRUQ3sgpKkjq\nI2lq3D9e0n2SHpb0mqQrE/ntL+k5SeMl3ZOIcLtc0rRY1tXx2NqS/haVEMZK2r2VL99xHKc0zRQF\nJ6k98Hvga0A/4ChJ+VE35wETzWw74FgqGB9vsw4oobSwj5ltD+Tm7qwP7AEcCBQTN+0PHEFYbO4I\nSRtLWivmt6+Z7QiMA34cw8gPBbaONza3IN21wG/MbCDwbeCmIvUcImmcpHGvzks779ZxHKcJmFW+\nlWYQ8LqZvWFmi4G/AofkpelHiG7GzKYDfRTl1opR9SCEJlBIaQHgH2bWCEwrcfGjzWwugKRpwCZA\nL8INfCbm0wl4DpgLLARulvQA8EDMY1+gX0KObnVJ3c1shdXFkkoIx/X5tishOI7TejTf2M6GwNuJ\n97MIUmVJJhGCyZ6SNIjwu7oRUDSOvy07oGIk1RKKiZUWUlQQQabnqPzE8WZ+BTgMOI3g/NoRdO0W\nNkelHcdxmp0UDiipWxkZFh+gK+Vy4NookzaFMPezoZRBW3ZAjwF/l3SNmX0YlRaawvPA7yVtbmav\nRwWEDQnCp13N7CFJzwBvxPSPAKcDVwFI6m9mE5tYB8dxnOYjRRh2sremAO8AyRnTG7Fc1SZn/ylB\nxBmFrqE3Wf57WZA264CKKC00Jb//SToeuFPSavHw+cA8gjJDZ0Ir6cfx3BkEhzWZcB+fBE5tSh0c\nx3GalYaSDZA0jAX6StqU4HiOBI5OJpDUC1gQx4j+H/BkTgi6GLLyg09OM/HOrvukvtnDZ6+fqazD\nunxUPlEeGx6SXipotXOuTm0DcP8256e2ebpz+v7sLZdme8aanyE8Z92Mclpf2+nt8ony+PD19J9V\nrw0+L5+oAE9M2yi1zfjVsv2u7P15+s+4Z/vFqW06dcj2w9x5tfQrjK4/INt973Xn40XXO6uUz289\nt+IPossJV5YsT9LXgd8C7YFbzOzSKCSAmd0gaVeC8o0BLwMnmdnHpfJssy0gpzhZnI/jOHVIM04w\nNbOHgIfyjt2Q2H8O2CJNnu6AHMdx6hWX4mldJJ0h6RVJH+dm60oaKunsuH+RpJWUsfPyOFXSsa1R\nX8dxnJbCGq3irRrUYwvoB4TJpLMKnTSzX5bLINmsdBzHabPUuBp2XbWAJN0AfBH4l6QfSbq+QJrh\nCYmemZKulDQlahdtHo8nW0xjJF0Rz78q6cvxeGdJt0bbCZL2br0rdRzHqYCGhsq3KlBXDsjMTiXM\n29kbKBl9kWCumW0LXE+I8ChEBzMbBJwFXBCP/TAUadsCRwF/jqHaK5CU4rnj/dkprsZxHKeJuBp2\nzXNn4nXXImnui68vAX3i/h7AHbBM9+gtCkSAmNkwMxtgZgOOWXeD5qqz4zhOeWrcAdXjGFBarMh+\nkpx0T062x3Ecp/ap8Xme3gIKqti51+dS2D0FfBdA0hZAb2BG81bNcRynCXgLqOb5QpTTWUQYy6mU\nPwB/lDQFWAocb2aLytg4juO0HlUKr66UVVqKR9JMYEBuSYeW5s3t90t9s9c5Mv240UvXLkhtA3BB\nh09S25y+dO1MZR009ZLyifKYvf+Q8onyuPXDksuRFOXs78wvnyifjP/s0+9O3xFxDp+ltnl3cfrP\nF+C8jlumtlm9IdsT9f5DM3yf5paUGyvI0lcLztIoy3ceSf/M3qvdauUTFeCut/7RZCmeBVecUPGX\nsutPbm1yeWnxFpDjOE6dYjU+D2iVdkBm1qfadXAcx2kxarwLri6DEBJyPCNaKP/jC01ydRzHqSms\nsfKtCtRrC2glOR5JHcwso2C+4zhOG8RbQK1LnhzPXEm3x5VMb5fUXtJVksZKmizplGgzOEru3Ctp\nuqQRcUU/JA2U9KykSVGOp0csagNJD0t6TdKV1blax3GcEixtqHyrAnXngPLkeH4D9CO0ho4CTiJI\n7wwEBgInxxX+AHYgSO30Iziw3SV1Au4CzjSz7YF9gdzqUv0Jc4e2BY6QlFyudhlJKZ47P8wWeeM4\njpMJ74KrOiPNLOc09ge2y4mRAj2BvsBi4MVcl52kiQTJnbnAu2Y2FpateU5sHI02s7nx/TRgE2Cl\npS2T66xnCcN2HMfJTI13wa0KDig5YULA6WY2KplA0mCWy+1AZZI7adM7juO0KrUehl13XXBlGAV8\nX1JHCBI6krqVSD8DWF/SwJi+hyR3NI7jtA0arfKtCqxqP6Y3EbrWxscgg/8B3yyW2MwWSzoCuE5S\nF8L4T8nVVB3HcWqGGu+CW6WleFqbh9c9MvXNHtY5vazOCYtKNeqKc9bS9Fqqh3RfaQWKijhzjfTq\nRxs8Miy1zbU7ll0AtyAvt/u8fKI8rj+le6ay/vW79LMDhsx/MbVNp/bZnjeHr7Z9apttv/hBprL+\nPiu99NSiDAIypxw+L70RsOeID1Pb9GzfJVNZj896tMnSOPN/fHDFvzndrxnpUjyO4zhO82A13gJy\nB+Q4jlOv1LgDWtWCEJoNl+NxHKfm8fWAah+X6XEcpy7xFlD1kfQLSTMkPS3pTklnR+md30oaB5wp\naW1Jf4syPWMl7R5tu0m6JcrwTJB0SIH8vyHpOUlrtfrFOY7jFMPDsKtLnMPzbWB7oCMwHngpnu5k\nZgNiur8AvzGzpyX1JswZ+hLwc+AxMztRUi/gRUn/TuR/KPBj4Otm9nGB8ocAQwBO7zGAr3fZrIWu\n1HEcZ0Us48KArUXdOyBgd+CfZrYQWCjp/sS5uxL7+wL9oswOwOqSuhPkew6WdHY83hnoHff3AQYA\n++dkevJJSvFkCcN2HMfJTI13wa0KDqgUSZmedsAu0VEtI05Y/baZzcg7vjPwH4Jw6RbAuBauq+M4\nTipqPQx7VRgDegY4SFLn2KI5sEi6R4DTc28k9Y+7o4DTE8sz7JCweYvQvXebpK2bveaO4zhNocbH\ngOreAUUl65HAZOBfwBSCynU+ZwAD4jpB04BT4/GLCWNHkyW9HN8n858OfBe4R5IP8DiOUzs0ptiq\nwCohxSOpu5nNl9QVeBIYYmbjW7se/1zv6NQ3e3in9JIhW7frUT5RAcY3fpLa5pDGNTKV9W779N+7\n7pZeKeTM8ReltgE4YaezyyfKY2N1zlTW0Ur/GV/UmP7ZcU5DelkngAuX9kpts83O2aR4Lpm0fmqb\nLhmeo/tn0e8BpndKb/ORsi329puZf22yNM4nR+1d8T9arzsfL1mepAOAa4H2wE1mdnne+Z7AHYQx\n8g7A1WZ2a6k8V5UxoGGS+hECCP5cDefjOI7T6jRTy0ZSe+D3wH7ALGCspJFmNi2R7IfANDM7SNLa\nwAxJI8xscbF8VwkHZGZHV7sOjuM4rU0zBiEMAl43szcAJP0VOARIOiADesTx8u7AR0DJCf51OwYk\n6dmU6QdLeiDuHyzppy1TM8dxnFYixRiQpCGSxiW2IYmcNmTFFZ9nxWNJrifMnZxNGGs/06z0Wt91\n2wIys92aYDuSELjgOI7TZknTAkrOWczIV4GJhPmRmwGPSnqq2BxJqO8W0Pz4OjjK7twrabqkEYmQ\n6gPisfHAtxK2y4RGJR0k6YUow/NvSevG40OjRM8YSW9IOqMKl+k4jlOc5ouCewfYOPF+o3gsyQnA\nfRZ4HXgT2KpUpnXrgPLYATgL6EeYOLq7pM7AjcBBwE7AekVsnyZMUN0B+CtwbuLcVgSvPwi4ILfU\nd5Jks3bUgteb63ocx3HKYksr38owFugraVNJnYAjWbmX6L/AVwDig/qWwBulMq3bLrg8XjSzWQCS\nJhKW5Z4PvGlmr8XjdxA12/LYCLhL0vpAJ4JXz/GgmS0CFkn6AFiX0De6jGSzNksYtuM4TlZKj8Ck\nyMdsqaTTCBPz2wO3mNnLkk6N528gzJEcLmkKIOAnZlZy6eNVxQEtSuw3kO66rwOuMbORkgYDQ5sp\nX8dxnJalGSeYmtlDwEN5x25I7M8maGdWzKrSBVeI6UCfhHrBUUXS9WR5X+dxLV4rx3GcZsIaK9+q\nwSrrgKLo6BDgwRiEUGzq9lCCzM5LQMnmpOM4Ti1R6w5olZDiqRWGb3hM6pt9xK3po8mvPTnVFKhl\nXPK/Z1LbXLjW7pnKOuXw9PIzp9+bvodzScbv960vXZ3a5k87/DJTWestTV/Hc5dMK58oj/cXrLRc\nVUUcs87A1Db/s0XlExVgxEX90ht17pLa5JpzX01fDnDhe0+ktlmzy+qZynr3k2lNluJ5f/Dgir9c\n644Z0+Ty0uJjFo7jOHVKtVo2leIOyHEcp06xxlZv1KRilR0DylFKsqecnE9usqvjOE4tUutjQKt8\nC6iQZI+kDma2tClyPo7jONXGMixh0pp4C2hFyZ6nJI0kKrwmzq0v6UlJEyVNlfTlhP2lkiZJej4n\n0+M4jlML1HoLaJV3QHnsSFBw3SLv+NHAKDPrD2xPENwD6AY8b2bbExa6Ozk/w6QUz5jPXmvBqjuO\n46xIY4Mq3qqBO6AVedHM3ixwfCxwgqShwLZmloshXgw8EPdfIkj8rICZDTOzAWY2YHC3vi1QZcdx\nnMJYoyreqkFFDkjSupJulvSv+L6fpJNatmpV4bNCB83sSWBPgiLCcEnHxlNLbPlEKpficRynpqgL\nBwQMJ4jQbRDfv0pQl14lkLQJ8L6Z3QjcROiqcxzHqWnMKt+qQaUOaC0zu5sobWdmSwlP/KsKg4FJ\nkiYARwDXVrc6juM45an1FlBFUjySxgDfBh41sx0l7QJcYWZ7tXD96opX+n499XPGPxavkbqcQzpk\nk1w5d0l6myOXfiFTWd88sugiiUXR2unLuuRPGS4K2LAh/fDoKRMuylTW6K3PS21zNjNT23Rp3ym1\nDcAtq/VMbfPJ56tlKutzS9+L3bP94tQ22/ywe2obgCP+9GFqm24rLxNWEXe99Y8me4X/bPPVin9z\nNps6qmaleH5MWHxoM0nPAGsDh7VYrRzHcZwm01Cl6LZKqegxz8zGA3sBuwGnAFub2eSWrFhTyakY\nSOoj6egK0veRNDXuD5D0u5auo+M4Tktipoq3apCmvTuIEGbcAdhREmZ2W4vUqhlIqBj0Iczj+UsK\n23HAuBaoluM4TqtRF1pwkm4Hrgb2AAbGbUAL1qvJJHTaLge+HFUMfhRbOk9JGh+3QlI8gyU9EPcH\nSXpO0gRJz0raMh4/XtJ9kh6W9JqkK1vv6hzHccpT61FwlbaABgD9rG0uHvRT4GwzOxBAUldgPzNb\nKKkvcCelnel04MtxTfR9gV8RAjIA+gM7EJbmniHpOjN7u6UuxHEcJw213gKq1AFNBdYD3m3BurQW\nHYHrJfUnhJLny+7k0xP4c3RWFu1zjDazuQCSpgGbACs4IElDCCuvMnTtrTm8Z+9muQjHcZxyNDTW\ntthNpQ5oLWCapBcJT/sAmNnBLVKrluVHwPsETbd2wMIy6S8GHjezQyX1AcYkziWXfSyohGBmw4Bh\nkC0M23EcJyu13mdVqQMa2pKVaGHmAT0S73sCs8ysUdJxQPsy9j0JEjwAxzd/9RzHcVqGxhpfjqEi\nB2Rm6RdCrx0mAw2SJhEkhf4A/C3quT1MEf23BFcSuuDOBx5syYo6juM0J7W+HlBJByTpaTPbQ9I8\nwvjHslOAmdnqLVq7JmBm3ePrEmCfvNPbJfZ/EtPNBLaJ+2OIXW1m9hwrjhOdH48PJzi0XHkHNlvl\nHcdxmoE23QVnZnvE1x6l0jmVscaGC1LbrPN6eimeNb+YbaXwPd7YOLXN13bKFvQ3/e70sjozG5am\ntjm687zyiQowY2n6Z6sskjoAX3n5V6ltBg04N7XNGmSThDFL/33aeL25mcqa+N7aqW02W6NcJ8bK\nvHdnehuAAyx9/bpVUTWzLrrgJG1GGDdZJGkwoQVxm5l90pKVcxzHcbJT61Fwldbub4RxlM0JEV0b\nk0JZoCnkJHVaKG+X3HEcp26xFFs1qDQKrjFOxDwUuM7MrotLE7Q4CUmdlsjbJXccx6lbar0LrtIW\n0BJJRwHHsXwJ6mwdyimRNF9Sd0mjo3TOFEmHxHN9JE2XNFzSq5JGSNpX0jNRHmdQTFdMTicpudNd\n0q0x/8mSvh2P/1HSOEkvS7owUa+Zki5M1Gmr1rgfjuM4lVLrYqSVOqATgF2BS83sTUmbAre3XLVW\nYiFwqJntCOwN/FpS7o5tDvwa2CpuRxM0684GcqPCOTmdHYBfEuR08vkFMNfMtjWz7YDH4vGfm9kA\nwrjXXpKSEXRzYp3+GMtzHMepGRpTbNWg0uUYppnZGWZ2Z3z/ppld0bJVWwEBv5I0Gfg3sCGwbjz3\npplNMbNG4GWCPI4BUwhK2BAmk94Tl1v4DbB1gTL2BX6fe2NmuVXdDpc0HpgQ7folbO6Lry8lylqx\n4tKQ2IIad/vs2ZVfseM4ThMxVPFWDkkHSJoh6XVJPy1w/pwo+jxR0lRJDZJKhvGWmwd0t5kdLmkK\nBcapYkuhNfguYRG8ncxsiaSZQOd4LimH05h438jy6yslp1OU2NI7GxhoZh9LGp4oN1l2QRkeWFGK\n5/3Bg2s8Kt9xnHpiaTN1rUlqT3hA3w+YBYyVNNLMpuXSmNlVwFUx/UHAj8zso1L5lgtCODO+VnuS\nZU/gg+h89iaIfqa1Lyen8yjwQ+AsAElfAFYnKCXMlbQu8DUqdF6O4zjVppKWTYUMAl43szcAJP0V\nOASYViT9UYSVBkpSsgvOzN6Nr28V2lJVPzsGjAAGxJbYsYQxnTRcCVwWI/eKOd1LgC/EpuMkYG8z\nm0ToeptOCDt/JssFOI7jVIM0Y0DJ4YK4DUlktSErKv3PisdWIi55cwBh+k5JVMkSP3lSPJ0IEXCf\ntbQUj6Q1gfFmlrbFU5Mc2Psbqbvg3lw0J1NZa3TontrmX0elt5n94KLyiQpwyrz008MnzZ2Zqayv\nrNGvfKI8Xvrsv6lturZfLbUNwKAuG6W2+dO49Osffv6zU1PbAOw6Mr2qwZyF2ZQQBvXcPLWNZZjF\nssSyDbufsiS9gsdW3bLdi37/ebDJzZdH1j2y4puz//t/LVqepMOAA8zs/8X33wN2NrPTCqQ9AjjG\nzA4qV2alYqTLpHhi9NkhwC6V2GZF0gaE7q6rW7KceiSL86lXsjgfx6kXmjG67R2CAEGOjVg+rJHP\nkVTQ/QaVh2EvwwL/AL6a1jZlObPNbAszu64ly3Ecx6lXGlDFWxnGAn0lbSqpE8HJjMxPJKknsBfw\nz0rqV6kW3LcSb9sRlrAut5BbsyHp2ZZURHAcx6lHmmtF7qiEcxowirCG2i1m9rKkU+P5G2LSQ4FH\nzKwitddKpXiSfXlLgZlAq62G6s7HcRwnPY3NFwWHmT0EPJR37Ia898NJLFNTjkq74NoRYrpPMLOT\nCYu6tdpE1ArleEZIekXSvTEKA0m/lDQ2RrYNy6knSBoj6QpJL0YJny/H4+0lXRVtJks6JR5fX9KT\niQlWufT7R4mf8ZLukeSDL47j1Ay1LkZaqQPaLrn0QlQJ2KFlqlSUUnI8WwJ/MLMvAZ8CP4jHrzez\ngWa2DdDb9loqAAAgAElEQVSFFeczdTCzQYR5PxfEYycR5HgGAgOBk+Nk1KOBUWbWH9gemChpLcLi\ndPvGOo0Dfpxf6WRo43/np4+schzHyUpdSPEA7eLETACivEKl3XfNRSk5nrfNLDdH5w6CFhzA3pJe\niPOH9mFFCZ5CMjr7A8dKmgi8AKwJ9CUMwJ0gaSiwrZnNI0QB9gOeiemPo8AEWTMbZmYDzGxA7+69\nm3L9juM4qWiUKt6qQaVO5NfAc5Luie+/A1zaMlUqSik5nvwWpEnqTOgqHGBmb0fnUU5GR8DpZjYq\nv3BJewLfAIZLugb4GHjUzI5q8pU5juO0AFVcjLUiKhUjvQ34FvB+3L5lZq2phg2l5Xh6S9o17h8N\nPM1yZzMnjs0cVkEZo4DvS+oIIGkLSd0kbQK8b2Y3AjcBOwLPA7srLNJHTLdFE6/RcRyn2WhU5Vs1\nqLgbLYrOFdP9aWlycjz3x+60cawoxzMD+KGkWwh1/KOZLZB0IzAVeI/QjVaOmwjdcePj+NL/gG8C\ng4FzJC0B5gPHmtn/JB0P3CkpNwX+fODVplyo4zhOc9GcUXAtQWuP46QmyvF8ZGZzCGsS5Z/vAyw1\ns2Pyz5nZ+QSnkH98cGJ/DnEMKC7pcB7L1xHK8ee45efzGCFYoSJ6KP0afjM+npXaBuCo9XdObdNu\nvZLK6QXptcFrqW0A3p2yILVNp/bpv65zGtKXA/D+go/LJ8qjX69sY3xrZFjbMYusTpfLbiifqACd\n7v9eJrssvLPkk/KJ8qhETiyf/p3XS20D8HlD6rn7dOhUvY6wWpffr2kH5HI82cjifBzHqT+q1bVW\nKTXtgMxsNlByXMXMZgLbtEqFHMdx2hDVCq+ulPTtyRomTkqdWu16OI7j1AINqnyrBjXdAmotJHUw\ns6XVrofjOE5z4i2gKiHpi5ImSPqypFujfM+EGMKNpOMljZT0GDA6HjsnIcNzYSKvf0h6SdLLyUWa\nokTQpZImSXpeYdVUx3GcmqBelBDaFJK2JKzGdzxhKVkzs20Jy8T+OU5ShTCf5zAz20vS/gTVg0FA\nf2CnOPkU4EQz24mgAn5GjMwD6AY8b2bbA08CJxeoyzIpntfnz2yBq3UcxymMqfKtGtSjA1qbsBbF\nd+OS2nsQ5Hkws+nAWywPbHjUzD6K+/vHbQIwHtiK4JAgOJ1JhMmnGyeOLwYeiPtJSZ9lJKV4Nu++\n0mnHcZwWo9ZbQPU4BjQX+C/B8ZSbOJtcs0LAZWb2p2QCSYOBfYFd4+TWMSxXWVhiyychJCV9HMdx\nqk5dSPG0MRYTFkU6VtLRwFMEHTmiVE5vgnJCPqOAE3NLKkjaUNI6BAmgj6Pz2YoWXorccRynuagb\nKZ62hJl9JulA4FHgYmDbKOGzFDjezBYpT/3VzB6R9CWC6CoEyZ1jgIeBUyW9QnBcz7felTiO42Sn\n1qPglEXGwsnG9C2+nvpm/2xh+9Tl/LwxvQ3Ape3SN9iPXrJ6prI+b5f+kWudpekj5bsqWyfEiM7l\n0+RzmrKtUp/lX/Cozz9IbdNJ2Z43X5yaXnf48a3z1awqY2zn9N/d/gvT/8xu2v3T1DYAIxp6prbp\nmHGEf+hbI5rcLvl172Mq/nb933/vaPV2UF22gBzHcRzXgnMcx3GqRK1rwdVjEEIqJB0s6afVrofj\nOE5z05BiqwarfAvIzEYCI6tdD8dxnOamscY74dpUCyiKjU6XNFzSq5JGSNpX0jOSXpM0KK5Meouk\nF6P0ziHR9kdxwTokbStpqqSuUZLn+nh8XUl/j9I6kyTtFo+7FI/jOG2OWp+I2qYcUGRz4NcEpYKt\nCEtw7wGcTVhI7ufAY2Y2CNgbuEpSN+BaYHNJhwK3AqeYWf5qZb8DnojSOjsCL8fjzSLFc/fc/zbP\nHXAcx6kAS7FVg7bYBfemmU0BkPQyMNrMLM7z6QNsBBws6eyYvjPQ28xeiUtoTwb+ZGbPFMh7H+BY\nADNrIKgqQHA6h8b9nBTPh6wsxbNffoZmNgwYBtnCsB3HcbJS6/OA2qIDWpTYb0y8byRcTwPwbTMr\npHbQlzDBdINKC3MpHsdx2ipLVdvPvG2xC64co4DTFeUMJO0QX3sSutj2BNaUdFgB29HA92P69tHG\npXgcx2mT1HoXXD06oIuBjsDk2EV3cTz+G+D3ZvYqcBJwedR6S3ImsHfsznsJ6EeQ4ukQpXgux6V4\nHMdpI9R6EEKb6jIys5nANon3xxc5d0oB2xMT+28TghkAhscNM3sfOKRA0V8rUp/uif17gXtL1X/c\n/DVKnS7IvPb/S23zvNZObQMwfeGrqW3Gd+2RqaydF6Z/5tr2i+nlZ7qsk22Gw/8mppdc+WThapnK\n2ni9ueUT5THn4/Q2Wckiq7P3y7/KVNYjA36e2mZ0l/TfpZ99cX5qG4Anp6WXW+rRPtv3ojmo9TDs\nNuWAHMdxnMqpbfdTn11wjuM4Ds3bBSfpAEkzJL1eTD1G0mBJE+OcySfK5ektIMdxnDqloZnaQJLa\nA78nTDWZBYyVNNLMpiXS9AL+ABxgZv8tMMa+EnXbApIyas87juPUCc3YAhoEvG5mb5jZYuCvrDxe\nfjRwn5n9F8DMyg7a1pwDqlBuZ40ojzM5SuBsF22HSrpd0jPA7ZI6S7pV0pQoy7N3TNde0tVRjmey\npNPj8YGSno3SOi9K6hHr85Sk8XHLyfMMljRG0r2xviNyod+O4zi1gKX4S6q2xG1IIqsNgbcT72fF\nY0m2AL4QfxdfknRsufrVaithc+A7wInAWJbL7RxMkNt5G5hgZt+UtA9wG9A/2vYD9jCzzyX9H2Bm\ntm2cw/OIwrLcJxBUE/qb2dLo0DoBdwFHmNlYSasDnwMfAPuZ2UJJfYE7CZI8ADsAWwOzgWeA3YGn\nkxcSP8QhACf0HMQ+Xfs2641yHMcpRprw6qRqS0Y6ADsBXwG6EFaXfj5OfSlIzbWAIm+a2RQzayTo\nsY2OigM5uZ09gNsBzOwxwsTS3NKcI83s87i/B3BHTDcdeIvgpfclyPEsjec+ArYE3jWzsfHYp/F8\nR+DGODfoHoKDy/Gimc2K9ZwY67YCZjbMzAaY2QB3Po7jtCaNWMVbGd4hyJDl2CgeSzILGGVmn5nZ\nHII+5valMq1VB1RObqcUnzVzXX4EvE+4kQOATolzyXq6FI/jODVFMyohjAX6Sto09hYdycrL2PwT\n2ENSB0ldgZ2BV0plWqsOqBxPAd+FZVptc8ys0CLvyXRbAL2BGcCjwCm5QAVJa8Tj60saGI/1iOd7\nElpGjcD3gPSL1juO41SBpVjFWylib9BpBKmzV4C7zexlSadKOjWmeYWgHDMZeBG4ycymlsq3rT6x\nDwVukTQZWAAcVyTdH4A/xu6zpcDxZrZI0k2ErrjJkpYAN5rZ9ZKOAK6T1IUw/rNvzONvcUDtYZq/\nheU4jtMiWDNORTWzh4CH8o7dkPf+KuCqSvPUcjFnp6UZs+53Ut/snf+4Q+py7jhjWvlEBRjWmH69\noksbKhYWX4E9Lky/dt8tl36Y2uaN9ktT2wBcemGf1DZPnTszU1kLlL4j4uZOhRr8pXlnySepbQC+\n3WmT1DYfK5u62GXjLk1ts+Sua1LbPHdReokrgJMb0stVbdJ5rUxlPT7r0SZH1Z7Y57CKf3NumXlv\nq0fxttUWkOM4jlOG5mwBtQTugBzHceqUWl+Qrq0GIbQ4kp6tdh0cx3GaQoNZxVs1qLsWUFQjUIxa\ny4yZ7dZMVXIcx6kKtb4cQ120gKJczgxJtwFTCXNycucOkzQ87n8nyu9MkvRkPLZ1lN2ZGGV5+sbj\n8+Nrd0mjowzPFEmHJMp8RdKNUfn1kRg95ziOUxOkkeKpBnXhgCJ9gT+Y2dYUD5X+JfBVM9ueIOsD\ncCpwrZn1J0w0nZVnsxA41Mx2BPYGfp3QfOtLWGV1a+AT4Nv5BSb1le7//I0mXJ7jOE46an1F1Hpy\nQG+ZWbnlsp8Bhks6meUTSp8DzpP0E2CThIxPDgG/inOO/k0Q4MvFEL9pZhPj/kuUkeI5qMsXU1+U\n4zhOVppRiqdFqCcHlGz1JO9m52UHzU4FzidoGr0kaU0z+wuhNfQ58FAUN03yXWBtYKfYSno/kadL\n8TiOU7PUehdcvf5gvi/pSwR5nUOBeQCSNjOzF4AXJH0N2FhST+ANM/udpN7AdsBjibx6Ah+Y2ZK4\nnEP6WXmO4zhVoFrRbZVSrw7op8ADwP+AcUD3ePyqGGQgYDQwCfgJ8L0oyfMe8Ku8vEYA90c5n3HA\n9JavvuM4TtOp9Si4unBAZjYT2Cbx/l7g3gLpvlXA/PK45aftHl/nALsWKTpZ5tXl6rlezwwychlk\nWvbqMSd9OcADn61ePlEePVmcqSzmppeSWZRBKKRL1l7mzukDGnu2z3YvNlsj/ffCPk3/r5tVdqv/\nwvRD1KO7ZCsri6xOxyN+nN7m4p+ktgHo3XnN1Da92nUun6iFqPWJqHXhgBzHcZyVcSkex3EcpyrU\nehdcm4iCkzRY0m6J98MlHVbNOjmO49Q6ZlbxVg3aSgtoMDAfaLI+W3NJ9TiO49Q6Dat6C0hSN0kP\nRvmbqZKOkPQVSROitM0tklaLaWdKWivuD5A0RlIfglrBj6Jczpdj1ntKelbSG8nWkKRzJI2NsjoX\nxmP5Uj0bS5ov6dJYr+clFV2gJr/FlZDpWV/Sk7FeUxN1cxzHqTo+ERUOAGab2fZmtg1hVdHhwBFm\nti2hFfb9YsYxwu0G4Ddm1t/Mnoqn1gf2AA4kRrFJ2p8gjzMI6A/sJGnPmH6ZVI+ZvQV0A56PsjxP\nAidnuLajgVFxgur2wMT8BEkpnrvnpl/wzXEcJyu13gXXGg5oCrCfpCtiC6EPQcImt7Tgn4E9ixmX\n4B9m1mhm01gujbN/3CYA44GtCI4HVpbqWUyYKwRFZHQqYCxwgqShwLZmNi8/QVKK5/CevTMU4TiO\nk41VvgUUHc2OBEd0CfDNEsmXJupULng+KYOjxOtlsaXU38w2N7Ob47n8yRZLbLnbLyejs6xektoB\nnQDM7EmC83yHoDF3bJk6O47jtBq1LsXTGmNAGwALzOwO4CrCpM4+kjaPSb4HPBH3ZwI7xf2ksvQ8\noEcFxY0CTpTUPZa9oaR1mnYFK9XrYKBjzH8T4H0zuxG4ieBoHcdxagJfkA62JUjgNAJLCOM9PYF7\nJHUgdGPdENNeCNws6WJgTCKP+4F741o8pxcryMweiRpwz8UVE+YDx5BYHygjNwL/lDSJMIaVa00N\nBs6JMj7zAW8BOY5TM9T6PCBVa/BpVeST7+6T+mZf+Ez6BtwFO7+f2gbggheKBgIW5fjG/NUrKmOz\n/Raktmn3ha6pbf41onv5RAV4tVN6m7OGtC+fqADv3Zn+8/rB3PSdFxu0T3//AM5pvzC1zdpfnJ+p\nrMmT10tt01HpZ1TsOvWK1DYAPxlwXmqbjmTQkAKumHlnNsMEu264d8W/Oc+983iTy0tLW5kH5DiO\n46Sk1hsYbUIJobWQ9PM4p2eipM/i68+LpM32iOc4jtNK1HoUnLeAEpjZpcCl1a6H4zhOc1DrYqRt\ntgVURGFhpqQro8LCi7lIO0kHSXohqi/8O6d6IGloVGIYExUVzkjkX1btoFIlBcdxnGrQYI0Vb9Wg\nzTogCissAMyNCgvXA7+Nx54GdjGzHYC/Aucm8tkK+CpBPeECSR3zyimmdtAcSgqO4zgthishtBwr\nKCyY2dx4/M7Ea24huY2AUXFV03OArRP5PGhmi+LCcx+wXFUhRzG1g4qUFJJSPMNfn53lOh3HcTJR\n62NAbdYB5SssSPpl7lQyWXy9Drg+toxOYUWVhaSiwkqKCCXUDipSUkhK8Ry/+QZpLtFxHKdJrPJK\nCC1FAYWFnArBEYnX5+J+T4IDATguZTmuduA4Tpuk0azirRySDoirCrwu6acFzg+WNDcRSfzLQvkk\nactRcIUUFu4FviBpMqFlc1RMO5SgvPAx8BiwaYpyBuNqB47jtEGaq2UjqT3we2A/YBYwVtLIKAad\n5CkzO7DSfNusAzKzUQTtt2VE+Z2rzOwneWn/CfyzQB5D895vk9jvHl//TFDszrftnti/l+D8HMdx\naoZmjG4bBLxuZm8ASPorcAiQ74BS0WYdUFtkzOj0MiPXffRE+UR5zH9ht/KJCnBezw9T2yxckB80\nWBnfeST9V+9/S9PX79BO2aR4Ln4v/X1/7k/bZyrrAFs7tc0pS9L/sHzekK3HfUSn1VLbPDktvXwP\nwDsNr5ZPlEfvzmumttkxg6QOwBXjfpXaZukz1Xs2raRrLYekIcCQxKFhZjYs7m8IvJ04NwvYuUA2\nu8UeqHeAs83s5VJl1pUDMrM+1a6D4zhOrZCmCy46m2FlExZnPNDbzOZL+jrwD5avx1aQNhuE0JxI\n6iXpB3F/sKQHytnk2V8kad+WqZ3jOE42mjEI4R1g48T7jVge2AWAmX1qZvPj/kNAR0lrlcrUHVCg\nF/CDrMZm9ksz+3cz1sdxHKfJNGMY9ligr6RNJXUCjgRGJhNIWk9xIF7SIIJ/KdlvXlddcE3gcmAz\nSRMJEXWfSboX2IYwyfQYM7MYVngQ0AV4FjglHh8OPBCDERzHcWqCBmvqUmgBM1sq6TRC4Fd74BYz\ne1nSqfH8DcBhwPclLQU+B45MzJUsiDugwE+Bbcysv6TBhIi5rYHZwDPA7gQ5n+vN7CIASbcDBxIW\nyytKcmDv+z0Gsn/XzUsldxzHaTaaU2Indqs9lHfshsT+9QQJtIrxLrjCvGhms8yskaD91ice3zuK\nmk4B9mFFSZ+CJJUQ3Pk4jtOa1LoUj7eACrOSPI+kzsAfgAFm9nbUhutcyNhxHKcW8AXp2gbzgB5l\n0uSczRxJ3Qn9nY7jODVLc0rxtATeAgLM7ENJz0iaShg8e79Amk8k3QhMBd4jRIU4juPULLW+IJ07\noIiZHV3k+GmJ/fOB8wukOb6SMt7rmL7BuVbX1VPb3P/JVI7qlX5W/poDUpvQuODz9EZAr2d7prZZ\n3H5papvHGj6gf4f0M+XX7JL+vndbaSmpCu0yBCpt1W1u+UR5dOiULSLqtQXp71+P9unVEwA26Vxy\n2khBerVL3xPeEaW2gWyqBh12r15nSbUWmqsUd0B1SBbnU69kcT6OUy/U+hiQOyDHcZw6pVpjO5VS\n1SAESRvECZ+l0vSRVLB7zHEcxymOL8ldAjObbWblOkj7AO6AHMdxUlLr84BazQFJulzSDxPvh0o6\nO0aeIam9pKskjZU0WdIpMenlwJfjCns/knS8pPskPSzpNUlXJvL8o6Rxkl6WdGHi+ExJl8U8xkna\nUdIoSf/JSUnEdOckyr8wHusm6UFJkyRNlXREPL6TpCckvRTzWr9l76DjOE46vAW0nLuAwxPvDwde\nSLw/CZhrZgOBgcDJkjYlyOQ8ZWb9zew3MW1/wpLb2wJHSMqptP7czAYA2wF7Sdoukf9/zaw/8BQw\nnDCPZxcg52j2J0iHD4r57yRpT+AAYLaZbR8XrHtYUkfgOuAwM9sJuAW4tNBFSxoSnd64p+a/luZ+\nOY7jNIkGa6x4qwatFoRgZhMkrSNpA2Bt4GNWXOBof2A7SbkuuZ4Eh7C4QHajzWwugKRpwCYxr8Oj\n9loHYH2gHzA52uSUW6cA3c1sHjBP0iJJvWL5+wMTYrrusfyngF9LuoIgOPqUpG0IQqWPRvHX9sC7\nRa572RobN2x8TG2PCDqOU1fUehBCa0fB3UNoeaxHaBElEXB6XGp7+cEgDppPIamcTYGzgYFm9nFU\nqO5cwKYxz76RcB8EXGZmf8ovTNKOwNeBSySNBv4OvGxmuxa/VMdxnOpS62HYrR2EcBdhHYnDCM4o\nySiClHdHAElbSOpGZTI5AKsDnwFzJa0LfC1l3UYBJ0aZHSRtmGixLTCzO4CrgB2BGcDaknaNaTtK\nKitM6jiO05o043pALUKrtoDi+hE9gHfM7F1JfRKnbyJEvI2Pixr9D/gmoQutQdIkwtjNx0XyniRp\nAjCd0B33TMq6PSLpS8BzsVttPnAMsDlwlaRGwlpB3zezxbGr8HeSehLu42+BkuufO47jtCa13gJq\n9YmoZrZtYn8mYSyFuPTBeXHLZ5+898MTeRyY2D++SJl9EvvD8+yT564Frs0z/w+hdZSf50Rgz0Ll\nOY7j1AK1PgaUKkzPt5bbgCGtYdOaZdV6/fxe+L2odllZ61cvmy/HUDsMaSWb1iyr1uvXmmXVev1a\ns6xar19rlpW1fnWBOyDHcRynKrgDchzHcaqCO6DaYVgr2bRmWbVev9Ysq9br15pl1Xr9WrOsrPWr\nCxQHwhzHcRynVfEWkOM4jlMV3AE5juM4VcEdkOM4jlMVfElupyySuprZghTpOwFbxLczzGxJC9Vr\nDTP7KO/Ypmb2ZkuU1xpI2gI4h6Dwvuz/08zy1UCSNl2B/wN6m9nJkvoCW5rZAy1dX8dpCh6EUEUk\n7Q4MZfmPjQAzsy+WsEn9A5Ww3QPoa2a3SlqbsCxF0R9rSbsRNPq6m1lvSdsDp5jZD0rYDAb+DMyM\n17MxcJyZPVmmbhsWuKZyNs8AXzOzT+P7fsDdFtZtKomk9sC6eeX9t0T6tYGTCXqFSZsTy5ST6rqi\n5uENwEsEpfeczUslbO6K6Y81s22iQ3rWwvpXpeqW9Zqy2u1WwOa2MjarAd8uYHdRCZvdgYlm9pmk\nYwgCwtea2VvNcU2S9jGzxyR9q1BeZnZfmWtaF/gVsIGZfS1+b3c1s5tL2dUj3gKqLjcDPyLvx6YM\n9xB+oG5MYYOkC4ABwJbArUBH4A5g9xJmvwG+SlxLyYLgazn9u18D+5vZjFjuFsCdwE4l6nYFYYHB\naSy/JgNKOiDCP/H9kr5BuK7bgO+WsUHS6cAFwPuE5Thy5W1X1Aj+SVgb6t9UeN8zXtdSM/tjJfkn\n2MzMjpB0FICZLYiCvuVIfU1Z7STdDmwGTGTFe1HSAcWy5hL+RxaVSZvjj8D28YHp/wgPUbcBe5Up\np9Jr2gt4DDiowDkDSjogghblrcDP4/tXCSsFrHIOqOpaQKvyBryQwealjGVNJLRIJiSOTa6kfnk2\nk8rYrJRnBeXMAFbLeF3fBJ4lLDS4RYU2rwNrpr1/GeqW+roILeIfEBZUXCO3lbF5FugCjI/vNwNe\nbIlrasK9eIXY45LSbmoGm9x9+CVwUvJYc9+LjPdvbHydUI3ya2nzFlB1eVzSVYQnpmVPd2Y2Pj+h\npDXi7v2SfkBYFC9p81G+TR6LzcwkWcyvWwX1ezt2m1hcp+lMwg9JKcZJuonQuoLQIhlXxuYNQous\noidcSdfBsgVMRFg99z/AaZIwszPKZPE24ak6DQ9I+rqZPZTCJtV1RY6Lr+ckjhlQtFuW0Jp7GNhY\n0ghCq/b4CsrKck1Z7aYSFqIsuHJwCZ6VtK2ZTUlhM0/SzwjLqewpqR3hcyhFpnsRW99bk1j80kp0\nD0Y+k7Qm8TssaRfSfx/rAh8DqiKSHi9w2KzAeI6kNwlf2EJdK2Ylxo2i/dmEJcb3Ay4DTgT+YmbX\nlbBZi7A8xb6x3EeAM83swxI2qwE/BPaIh54C/mBmK/0IJxzJhsD2wGhWdKoFHYmk4wodT9j9udR5\nSTcTuuwezCvvmgJp57H8vneL6ZewfLxu9RLl/I0U19UU4g/aLrFez5vZnAps5pHymrLaxe96f+BF\nVrwXB5cpaxphTa43o12urKLdpZLWA44mtDSektQbGGwFxpua+PneAHQF9iZ08x1GaHmeVOaadgSu\nIyxFMxVYGzjMzCaXsqtH3AGtQkjaD9if8M81yswerXJ9muRIYh5dCNFfM1KUe0GR8i6sNI8Kyyl4\nfRU4yG2Afqz4VF10rCTLoHtrI6ng+IuZPVHGbpMidlW/NkmTzWy7xGt34F9m9uUKbDsQHoJEC0aK\n1jrugKpM2ia8pO8AD5vZPEnnE35sLjazCS1QtyuBS4DPCV082wE/srA8eTGb/Mg+AEq10GJ34EIz\na4jv2xPGTkqGfks6CLga6GRmm0rqD1xU7qk6C0V+5H9rJSLnMpZzATCY4IAeIiwt/7SZHVbCZjKh\npbUdYXD7ZuBwMys16J6z/QKhZZz8/pUL/shslxVJ6+SVVSpiMdeqAehE6H6bb2Y9S9ik/nwlvWBm\nO0t6HvgW8CHwspltXuZaCv0PX1Ko673uqfYg1Kq8EaLZbiOMSVxAGEi/uYzN5Pi6BzAG+AYlghmA\necCnBbZ5wKdlypoYXw8l/Kj1pHwQwnTCj+Y6wJq5rYzN84RQ79z77oQw4nL376VYp+RgbtlBa0KX\nx1WEH/jHclu5+054Wt0emEDoZnyijE1f4F5CFNwbua2MzRTCBPFJ8f26wKNlbFIPusc0/y+W9zHw\nOOFBo+R9yGpH6B4cS1jqfjEh0qzk9y/aHQy8BnxG6IZrJPzIV/o/JkKgyuUt8Pn+AuhFCBN/jzC+\ndXEFdUr+Dz9e7n+4njdXQqguu5nZscDHFrp/dmX5BM5i5EJEvwEMM7MHCU95BTGzHma2eoGth5Xp\n62d5C+YbwD1mVslA6Vwz+5eZfWBmH+a2MjadzWx+os7zCX3r5VhSoE6NBVOuyAiCo9wUuJAwZ2ls\nGZulFn41DgGuN7PfAz3K2NxKCAleShgnuI3lwRnF+NzC8vRLJa0OfECYS1WK3KD794AHKxx0hxBU\nMhB4y8z2BnYAPmkhu+uBowjOpAvBif2+grIuJjivV81sU+ArhAeWirDAPwjTCUqR+vM1s4vN7BMz\n+xuhxb+Vmf2igmol/4dvLPc/XM94FFx1+Ty+LpC0AaEJv34Zm3ck/YkQTHBFHPSv6EEizovI9U8/\naeUHPR+QND3W8/txst7CMjYVR/Yl+EzSjrk0knZi+b0pxcuSjgbaK8z+P4MQklyONc3sZklnWhiD\neEJSOQeUJbKqi5mNliQLYxZDJb1EaKkUY5ykXoR5Xi8RWgzPlSnnCMKg+4lm9l4cdL+qjA2Ebs+F\nkugPKFEAABfZSURBVJC0mplNl7RlS9mZ2euS2lvoar1V0gTgZ2XMlpjZh5LaSWpnZo9L+m0pA604\nQbQdYf5bue9tls93pcm1MQqz3NymzP/D9YY7oOryQPyxuQoYT+i3vqmMzeHAAcDVZvaJpPVZMWS3\nIJLOJMz0zk2SGyFpmJWIgjOzn8ZxoLlm1iBpAeEJsRQ7x9cByayAUkoNZwH3SJpN6AZZj/CjWo7T\nCZP5FgF/AUYRxqzKkRvwfTeOwc0mzLcpRe5H/qQUP/KL4g/Za5JOA94hdC8WxZarTNwg6WFg9XIP\nCrE+fyN0+QHMIYTpl2NW/P79A3hU0sdAJYP7WewWKEg0TYzfqXep7Ef3kzi4/yThO/sBoTuuFMkJ\noksJLdxy39vUn6+yT67N9D9cl1S7D9C3sAGrAT1LnF89vq5RaKsg/8lAt8T7bpSfINoVOJ/Q1Qfh\nB+7AFrr+joSw1G2Ajiltu6ZMfyBh7GgbQh/8S8DBLXBNAwkOZyNCd9x9wC5lbA5Nfg8IYwzfLGNz\nMqEL8T+Jz2l0yrruRRhv6dQSdoQuqs7A6oTxzmuAzSvIvxvQnvCwfByhlZtqEnGBPH/WTJ9vpsm1\n0XYP4IS4vzawaXN//9rC5lFwVUAZtKQkPWBmBxaZD2RWfh7QFGCgmS2M7zsT5klsW8KmYo0xSceY\n2R2SflzkmlaaY5Nnn0UnLLVWXVokPW1me+RFVkGFc2YylDcx//5KmmBmO5SyAQYRBrJ3iMemlPps\nE7ap9AGjzS6EQIB58f3qwJfM7IUSNt1YPr5VcaRjSyBpvJntGPczf76S7gHOMLNUk2uVkMUysy1i\n9/s9ZlZKFqsu8S646rAXKbWkzOzA+LppxjJvBV6QlOua+SbltafSaIzllBXKDcyvRBO6MlJp1Uk6\n18yu1IpKCsuwAhNEzWyP+FrxdUn6rZmdJen+IuWUChMv1C1V7v90kZktzn00CnNMyj5ZKps+IITA\nih0T7+cXOJbPaMKE5lywSRfCxObditStJR3/su9wxs8397n2AKZJSjW5ltDK3YHQ7Y6ZzZaU+v+m\nHnAHVAXM7IL4ekJaW0mjzewr5Y4VKPMaSWNYrlBwgpWfO7RYYaJnTjJkM4rIypjZn+JrlsmcA4B+\nlqE5bmZv5/nEUkKSORmhctJAKxCf1l82s60qNLk9vl6dppzIOEnXsDxC7IeEVmgpnpB0HtBFYbLx\nD4D7Kygr6w+hkp+VmTVGp1eKlSIdY4u6IFkcQwoKfs9UuUL61QQndgXhQW5ZFvFYObLIYtUl7oCq\nQLFuqhyFuqtil1lXYC2FSYC5X93VCVI2ldAVmJfrblH5tXNSa4xJ+iJBvmcXwj/6c4TJq2+UMMuq\nE5ZKq87M7o+vZRUW8uwaJM2Q1LvID1J++pfia8lZ/kU4nTC/5K74/lGCEyrFT4GTCHNzTiHMbyoX\nzALZfwjfkHQGodUDweGV+nwhY6RjfOiZZWaLFJb62A64zcwqCRcvmm2BcipWSM99rpI65n/G8YGt\nHHfHKLhekk4myGLdmOoK6gQfA6oCKiIFk6NQKyJGsZ0FbECI2srxKWEuwfUVlJm631kpNcYUZoX/\nnrAEA8CRwOlmtnMJm6w6Yam06op1iVVSnqQnCa2FF0lEYRWy+f/tnXu0XHV1xz/fkEREJUUEFywR\niNLVBkUxUKW+gBZxCcjDEMt7UZQIrmoUBQtS6gMfKOXVoliMIqTLAlphqYikaBZJeAZCSEDqi2V9\nEaXyKPVB4u4f+3dyz507c15zZ87lzv6sNeveOXP2nN/cO+fs89u/vb87rbcVHaeo7cPQUAN9wGS3\nPXAxntloeHhtsZltKLDZG/gy/t3dnOloBX2Okt0a/Hu7C+5YrwN2N7M3VfiIvd7zTDP7WMe2HwCv\n7PXd6dj3FNzpzsVFcDOeA6w0s2MrvMeUksVqi3BATzMk/V3ZBaKH3RpSuCW3UL227GKo+g3VJryn\npHvN7GUFNrV1wlK45F1mdkHB8Hsd5wj8ApgVhR4FPGxm75mMMaqHflnOZkLKcj/rRmrQ2DBnO7QL\nYZqlZvVClfTPsoQBSe/H648uqZCUUbthXroJOsDMNlYY0xxgG9xpfyD30hNWrkqff5+tO8ZX2Xa6\nEA6oBZoshqv/Lox3mNlf5E7oZwG3FjkgjTVUW08uLFFyMfwkLtHy5fTZ3oqfrJ9Kxl1PsnTR3s3M\nlqW1gS2yLKuCY91pZnsX7dPD7i4z26ts2zCRNN/MVjd0xt+jS2PDorv55MCXmSsZVB1j7e9tzvad\nwNIsdJbCyEeZ2aUlx7wduBCv9zrEzH4saZ0VdL2VtApXYe/8e3ylwKayQnq/SFqEK3D8Dj+vKt8w\nTDdiDagdmiyG186c66BJ3PkwPGRXp5/NwvRzUcf2v0njnHCSpfGcjNc0vQhf0/osLrtSxApJ/4yv\nl+TDYmWijs+SNDdbl5K0K2NZfJ1j6ydN91W47P6f41IrWwBPdrPpc93oMTO7oY5BWtf6o6Q5Vk1i\nCRomcSTebi5vkx3/N+n/XuiAgBOBdwDnJuezK2NJHr3YyszOqDm+n6THbAYvi/M+4CVl4exRIGZA\nLSLptXhdzabctlf0uoDKq+oXmNnVDY9XK9wi6QbgyHz20iBQwzoWjfVTyr7EmVMoUl1A0huBz+EL\n58JDV4vM7Mbmn6Lrce7CHe81+DrG8XjX1p7yM3JJoY8zsR1DkZr4J3DnVkf+CEnX4WHZmxjvwAv7\nFUna0lI9WW7b84ouqGldbA9LF5w0A1trZrsXHavjPbYBdrISZQhJH8XPq7qN9oaCXOHiCGuhBmqq\nEQ6oReTSNnfiF/kNadvmIrkeNrVDRU3CLcmuckO1fkKEGpO1v8fM9pSn9N5dYX3qNMYX5RqelHGX\nma0psX0GkKVVf6/mLK8S2f8qvy5WYf1iBZ6NdQE+2z0RmGFmPfXjVKOxYYfdCd22W3m/orXAyWZ2\nW3r+FuDjZtZTSFeuD7gzcFnatAj4bzM7reRY38WVFmbiIbUN+EJ/z0xSNWuYtx1wOhNboxT+DZsg\naU9SXR4DblQ41YkQXLs8iK+NLJd0kpmtokuKaAfLUvZSZ9ip5wJmw3ALeIHn9RX37SdEuFzN6ljm\n4zOL6/G/28G45NAiSdeY2Xkltrvg58DLVE1Esi5N9M9qC5jWvbHI2V2Rxpc5jqqN0Y4BliTnsCPe\ncqPsQn0G7nROSc9volqq+Bwze1zS2/D063OSA+yKJOFZcnX7NC3Fz6mD8ZDfCcCvar5HVS7Dz5X7\nqKbePm2JGVCL5BICdsO//EtwReOiGVAmxTOOsgXMpuGWYZBCiyeRCw8Cl1vJl1OeGv2mLEQoF638\nBi70uNrM5vWw66q8MNl/i5RY8TC+pvAeXH/uX8zshwU2q/Bi4Wvxi9TP8F42hWrTqtnYMNnsC1yB\ni3UKb/twglVrSHcYvhbzBPA6M/tBBZvZ+EK/UT0L7j78e3EFcJaZ3amS7M0q4dsuNqvNbH7HbLVR\nkkuFYxXOgkeJmAG1iwDM7PtyCZkldCl862AePkN4DX4i34Iv2JfxVcoTFXxQ0tVmtlA96lm6nfxq\nUFyb7LbA72yPoX4x3vaMV2Z4Cni+mf1WUlFIrbHyQk0OM7OL8GynDwFZPddFBTbvxguG34X3wtkf\nvxvviaTPJpv98FnFArxeqYzzgTdYamcu6U/x+q35Jcf7PO7A98BnT1+XdEk+yaCLzb50ODtJVZzd\nh/EbkhXJ+czFewoVcbekvc2srMVGniYK6U25QdLJ+Cw/H4KLNOygXVRSbS/panydY2nadDQepljY\nyybZVW57LWkHM/uFetSzWPc6ltrFtTnbFcD+ZvaHovfoYnc2LidzXdp0CB6OOx9X8D6mh10jEcm6\ndFvPG8Tdb3bXnvv5bOAGM3ttFbuybV3sFgMX5RIK5gD/ZGYnFdisBo7udHZmVujsmiBPS38x3iLi\nScbWgIpmTQfjN3M74ZmLWwMfMrOqIeg64+umPmJlUYzpSDigFpHL65zExNBJUcHc/Z2hpW7butjd\nBvx1R7jq22bWVQxymEj6Ep6qfD3jw4OlNRiS9mJMPHOlmZWmCKuh8kJV5OKtR+Oz1FtyLz0H+KMV\n6Palz3MWE4t/iy6eWRLHbXiR7SO4dt2LS8a5BF+DyApyj8WvCT0dSc72mcALM4dSYf+mzu4LdJ+F\nF50jlW+cgnaJEFy7XIm3hj4QDzUcQ4GWWeJuSa/KZSC9kmp1GbXEINN7H4GLK26P30X2zCZSs+La\nK83sODzL6QJ8gb6W+GRyOHXrUv6x5v51WYUnHDwPn41lPIEnSRSxFG9OVmeBultjwyrhzCV4+nv2\nv7mF8vAWkg7BBTlnA7tKejnw4RIHfpekyxlzdsdQ7f/29dzvW+Iz3p/32BdwR6MubSaKbDSmYbgP\n/nevomHYGEkvYWKq/WQnwUx9bAo0JRrVB3BP+rk2/ZyF66112/c+/OL1AH6CPAT8OP1+f4VjrQRe\nkXs+H1dCKLL5Ad7npcpneST9XIyvWYx79LC5H8+iWkuDJnvT8YGvdfRjX9jYsGPfu4GX5p4fhddi\nldmtxhMq7sltW1dhXO9lbC3yPXgIuO7nm4HX+BTtcw6+vvJf6fmO+Oy4yOY24Dj8pnwmPhss/Vs0\n/B+dgzdCfBhPx/4lcG3b3702HjEDapds4fPRdEf0S3y20Y2D+zxWk7bXD5tZ2Yxs875ygdMTgX0p\nTycHT574T2BXxt8Nix6qCf2gITWX6/M456SZQmftVVEd1ZaMT0xZIekz1lEs2oUF+HfiaOB1eKHs\nG0psAJ4ys8c0vg1Gz9laWm9cYr4m16+0zW70PkcymrSZ2MrM8goLV8n15wbBAry+7h4zO1HS8xmb\nGY4U4YDa5XPy6u4P4usfz8al+CdgfcavzTOI/oweYpCSDrCkjKCxYtK75F1Rv0b5xfAz+EVzLuP7\n1/R0JmZ2MXBxulie0vn6ZGOD7TEzWcc5ES+QncX4tgBFGYxfwsN7mUjt0Xh498iScf4orVd9DZeh\neYOZlbZIANYnp7VFKiF4Fx527HWcTZJ2ljTbaiSapJqeTYw1sQO/SSuT2WnSZuIGSR9gvIbhNyU9\nN32GycxQ+615D6WNckHSDXjyw8gRSQgtoT5ldSYbjW9T/IW0Oa8ykGFWvAA8FGcyXZH0oJXU/HSx\nqZWY0iW9fnvgMdJNhpUnBmyFJ0pks6UbgY9YgZpE00QTlQiP9rCp3WaiIzMtL+2Uhjl5GWqSLgXO\nxGWaTsMd7Bpr0KDy6U7MgFoi3QGdDkwJB0TO0WQngqQr8P46eQXj87ubb7YN59MfqyTNM7P7a9jU\nTUzpN5w7Lz2y9ZJD8USSIsf1w/Som2iyum5Nj5l9Wq6o8Tg+4/8HK28zcQbwLXPVhbPx9uIfsXJh\n29qY2anp18/KdeG2thJ9u+lKzIBaRC4i+WtqyOoMcCyValYGUccSjCHpAbzI88f4jKRKDcsD+IU2\nqx97IS7ztLHMtuEYH8QVndeRW/upEiZO6f9YRYHbJjU9TcjVUL0GLwD+NO64ejZS7PN4tfpsTVdi\nBtQub8Wn+6d2bJ8qBWkzJG1jZr8BSPHw+M4MljcOyaYffmWpvXlVUpLNlSR1AUm/Bo43s/UlpgfW\nHVyd8oEcmSTTQXiH4W/IVbUnHY312bo/d1wDwgEFQ6WprM4geKjLtvOBW+XKAeCL2ucObUQjSDaL\nkLe93rJk90Ibqy/IWZXamXp4+4v3mtl30lj3xWuVCguhGybfnIc3r6uawQnwM3m/rAOAT8rV0suE\nY5vSpM/WtCRCcC2ihrI6fRzvL5nYpriw+E3SPMaUjm+uuTYR1ETSm3HHvyOeHbUz8IAV9M1pYtPn\nGK/CM/U6O+UWJadMaMvebdskjW+lmb26fM9xNlvhM8n7zLUZd8BrpL49gPENpc/W04FwQC1SN3up\nz2MNRQE66A9J9+IOf5l5b6T9gGOtWGettk2fY2ySqfcfeF1OVmtzLDDfzA6fxHFl5QOvx+vcqpQP\nDB3V6LM13YkQXLs0ldVpwrAUoIP+eMrMHpE0Q9IMM/uOpAsHYNMPTTL1/hZXBP9Ken4LXvM0meR7\nUf0f44tqq7StHxbd+myN5HkZDqgFcnUYs/CT+Sfp+c64NtwgWIffFQ5UATrom0dTptgtwFJJG8hl\nSE6iTT+8Cm+yVzlTD59974Svq8wE/gqftU1aNluufODVZrYy/5qkWiG5AfMn5m06NiNv0zFyRAiu\nBdRDrTejX9WDHsccqAJ0MDmktYjf4Rf1Y/G2AEuLUvOb2PQ5xtpq0/2kbjcYX7eSgsJW98OkasnD\nKBAOaESQ9Ppu281s+bDHEkxE3fXjsuLgPwL/A3zKzC7tx6YtsrEO+Bj74Fl1i3F19YytgcMHkfBQ\nB/XRpmO6EiG4ESEczdTGSvTjJG2L661d2o9NizRJ3a7LbFxPcSbj1RYexwVA26afNh3TkpgBjQgd\nd8mz8fWnJ0uK84IphFKn2kHbDIImqdt9HGvnQYT2JpMUxtzNzJbJm/vNNLMn2h7XsIkZ0IiQv0tO\nKsOH4ovJwdOEJo5kKjifxN51U7f74IuZEnYeM9u/287DRtLbgZNxVYgXAS/AC9BHLgQXM6ARZlQX\nPoPhkxTWPzWMQmZJ83NPtwTeAmw0s9MHfewqSFqDd6K9PTv/JN1nZi9td2TDJ2ZAI0KuSA88FXYv\nPHMqCIZBk9TtRpjZ6o5NKyXdMdnH6YPfm9kflBr6SZpJ1AEF05x8kd5GXPvt0HaGEowgQxNMTaK5\nGTPw9vNzhnX8CiyXdCbwzNQ24lS8hfjIESG4IAimFWmWlTVT3Ii3tviwma1odWAJeTPKk3ClBuEN\n/S4fRZWScEDTHEmnm9l5ki5h4jTf8FqRq8zsh8MfXRAEo0yE4KY/mSR9L425bXGNrFaL9IJgspA0\nCzgFeF3a9F3gMjN7qrVB4er3ZrZQE1uiA+Wt0KcjMQMKkLTIzC5rexxBMBmkgtdZwBVp03HAJjN7\nW3ujGqvJknQacBvw0/zrU712aRCEAxoRJG2H972fx/imZVOiNiIIJoth9h5qgqRzgIV4+PvfgWvM\n7OF2R9UOg+r4F0w9luLhuF1xWfyHgDvbHFAQDIhNkl6UPZE0l7EeWK1jZh9KzQLfCeyAZ8Uta3lY\nrRBrQKPDtmb2eUnvTrpwyyWFAwqmI+8DviPpR+n5Lkx+76HJYAPwS+ARYPuWx9IK4YBGh2wB9heS\nDgJ+jkuBBMF0Y1vgJbjjOQzYB3iszQHlkXQqHoLbDrgGePuotroPBzQ6fFTSHOA04BJcon5xu0MK\ngoFwtpldI2lrYD/g08BngFe2O6zN7AQsNrM1bQ+kbWINaHQ4Ek86WWdm+wEHAIe3PKYgGATZes9B\nwL+a2TdwBfgpgZn9fTgfJxzQ6LCHmT2aPUndMkOINJiO/EzSZcBbgW9KegZxrZuSxD9ldJghaZvs\nSdLLihBsMB1ZiMvbHJhuup4LvL/dIQXdiDqgEUHS8cCZ+KIneEjuXDO7sr1RBUEwyoQDGiEkzQOy\nwtObRzXzJgiCqUE4oCAIgqAVYg0oCIIgaIVwQEEQBEErhAMKgiEhaUdJ15bss2pY4wmCtok1oCAI\ngqAVYgYUBH0i6XhJayXdK+lKSV+UtCD3+v+mn7tIWpd+313SHZLWJNvdOvbdV9J3JV0r6XuSlkpS\nem2+pOWSVku6UdIOw//UQdA/4YCCoA8k7Q58ENg/9Zt5d0XTdwAXmdnLgb3oaE6W2BPX65sHzAVe\nnbp9XgIsMLP5wBLg3P4+RRC0Q1TCB0F/7I83FPs1uMRRmqiUcStwlqQXAF81s+932ecOM/spgKQ1\nuLrzo7jS803pOFsAv+j3QwRBG4QDCoLJZyMpuiBpBl2EMM3s3yTdjgtmfjO1Rb+5Y7ff537fhJ+v\nAtab2T4DGXkQDJEIwQVBf9wMHClpW9issfcQMD+9/mZgVqdR6tL5IzO7GLgO2KPi8R4EtpO0T3qf\nWSkMGARPO2IGFAR9YGbrJZ2Ld5jdBNwDnAFcJ+le4FvAk11MFwLHSXoK74r5sYrH+0NKcLg49Xea\nCVwIrO//0wTBcIk07CAIgqAVIgQXBEEQtEI4oCAIgqAVwgEFQRAErRAOKAiCIGiFcEBBEARBK4QD\nCoIgCFohHFAQBEHQCv8PUSa8LYI2BjQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ef1add8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the similarities as a heatmap\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(cuisine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hand-selected cuisine groups\n",
    "group_1 = ['chinese', 'filipino', 'japanese', 'korean', 'thai', 'vietnamese']\n",
    "group_2 = ['british', 'french', 'irish', 'russian', 'southern_us']\n",
    "group_3 = ['greek', 'italian', 'moroccan', 'spanish']\n",
    "group_4 = ['brazilian', 'cajun_creole', 'indian', 'jamaican', 'mexican']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Model stacking\n",
    "\n",
    "- The term \"model stacking\" is used any time there are **multiple \"levels\" of models**, in which the outputs from one level are used as inputs to another level.\n",
    "- In this case, we will create one model that predicts the **cuisine group** for a recipe. Within each of the four groups, we will create another model that predicts the actual **cuisine**.\n",
    "- Our theory is that each of these five models may need to be **tuned differently** for maximum accuracy, but will ultimately result in a process that is more accurate than a single-level model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brazilian': 4,\n",
       " 'british': 2,\n",
       " 'cajun_creole': 4,\n",
       " 'chinese': 1,\n",
       " 'filipino': 1,\n",
       " 'french': 2,\n",
       " 'greek': 3,\n",
       " 'indian': 4,\n",
       " 'irish': 2,\n",
       " 'italian': 3,\n",
       " 'jamaican': 4,\n",
       " 'japanese': 1,\n",
       " 'korean': 1,\n",
       " 'mexican': 4,\n",
       " 'moroccan': 3,\n",
       " 'russian': 2,\n",
       " 'southern_us': 2,\n",
       " 'spanish': 3,\n",
       " 'thai': 1,\n",
       " 'vietnamese': 1}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary that maps each cuisine to its group number\n",
    "cuisines = group_1 + group_2 + group_3 + group_4\n",
    "group_numbers = [1]*len(group_1) + [2]*len(group_2) + [3]*len(group_3) + [4]*len(group_4)\n",
    "cuisine_to_group = dict(zip(cuisines, group_numbers))\n",
    "cuisine_to_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  group  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...      3  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...      2  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...      1  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']      4  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...      4  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the cuisines to their group numbers\n",
    "train['group'] = train.cuisine.map(cuisine_to_group)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that all recipes were assigned a cuisine group\n",
    "train.group.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276513701245822"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the cross-validated accuracy of using text to predict cuisine group\n",
    "X = train.ingredients_str\n",
    "y = train.group\n",
    "pipe_main = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "cross_val_score(pipe_main, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define an X and y for each cuisine group\n",
    "X1 = train.loc[train.group==1, 'ingredients_str']\n",
    "y1 = train.loc[train.group==1, 'cuisine']\n",
    "X2 = train.loc[train.group==2, 'ingredients_str']\n",
    "y2 = train.loc[train.group==2, 'cuisine']\n",
    "X3 = train.loc[train.group==3, 'ingredients_str']\n",
    "y3 = train.loc[train.group==3, 'cuisine']\n",
    "X4 = train.loc[train.group==4, 'ingredients_str']\n",
    "y4 = train.loc[train.group==4, 'cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a pipeline for each cuisine group\n",
    "pipe_1 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_2 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_3 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_4 = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693031228079263\n",
      "0.7568885301219405\n",
      "0.8701840957938736\n",
      "0.9043403347972706\n"
     ]
    }
   ],
   "source": [
    "# within each cuisine group, calculate the cross-validated accuracy of using text to predict cuisine\n",
    "print(cross_val_score(pipe_1, X1, y1, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_2, X2, y2, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_3, X3, y3, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_4, X4, y4, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Ideally, each of the five pipelines should be **individually tuned** from start to finish, including feature engineering, model selection, and parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit each pipeline with the relevant X and y\n",
    "pipe_main.fit(X, y)\n",
    "pipe_1.fit(X1, y1)\n",
    "pipe_2.fit(X2, y2)\n",
    "pipe_3.fit(X3, y3)\n",
    "pipe_4.fit(X4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 3, 4, 4])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the new data, first make cuisine group predictions\n",
    "X_new = new.ingredients_str\n",
    "new_pred_group = pipe_main.predict(X_new)\n",
    "new_pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chinese' 'japanese' 'vietnamese' ... 'chinese' 'chinese' 'vietnamese']\n",
      "['british' 'southern_us' 'southern_us' ... 'southern_us' 'french' 'french']\n",
      "['spanish' 'italian' 'spanish' ... 'italian' 'italian' 'italian']\n",
      "['cajun_creole' 'mexican' 'indian' ... 'mexican' 'cajun_creole' 'mexican']\n"
     ]
    }
   ],
   "source": [
    "# then within each predicted cuisine group, make cuisine predictions\n",
    "new_pred_class_1 = pipe_1.predict(X_new[new_pred_group==1])\n",
    "new_pred_class_2 = pipe_2.predict(X_new[new_pred_group==2])\n",
    "new_pred_class_3 = pipe_3.predict(X_new[new_pred_group==3])\n",
    "new_pred_class_4 = pipe_4.predict(X_new[new_pred_group==4])\n",
    "print(new_pred_class_1)\n",
    "print(new_pred_class_2)\n",
    "print(new_pred_class_3)\n",
    "print(new_pred_class_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the cuisine predictions to the DataFrame of new data\n",
    "new.loc[new_pred_group==1, 'pred_class'] = new_pred_class_1\n",
    "new.loc[new_pred_group==2, 'pred_class'] = new_pred_class_2\n",
    "new.loc[new_pred_group==3, 'pred_class'] = new_pred_class_3\n",
    "new.loc[new_pred_group==4, 'pred_class'] = new_pred_class_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>['baking powder', 'eggs', 'all-purpose flour',...</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>['sugar', 'egg yolks', 'corn starch', 'cream o...</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>['sausage links', 'fennel bulb', 'fronds', 'ol...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['meat cuts', 'file powder', 'smoked sausage',...</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>['ground black pepper', 'salt', 'sausage casin...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \\\n",
       "0           9.333333  ['baking powder', 'eggs', 'all-purpose flour',...   \n",
       "1          10.272727  ['sugar', 'egg yolks', 'corn starch', 'cream o...   \n",
       "2           9.666667  ['sausage links', 'fennel bulb', 'fronds', 'ol...   \n",
       "3          12.000000  ['meat cuts', 'file powder', 'smoked sausage',...   \n",
       "4          13.000000  ['ground black pepper', 'salt', 'sausage casin...   \n",
       "\n",
       "     pred_class  \n",
       "0       british  \n",
       "1   southern_us  \n",
       "2       spanish  \n",
       "3  cajun_creole  \n",
       "4       italian  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.70475)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new.pred_class}).set_index('id').to_csv('sub5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
