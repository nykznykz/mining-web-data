{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging multiple csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "df = pd.DataFrame()\n",
    "for file in glob.glob(\"*ig.csv\"):\n",
    "    brand = file.split(\"_ig.csv\")[0]\n",
    "    temp_df = pd.read_csv(file)\n",
    "    if brand == \"samsung\":\n",
    "        brand = \"samsungmobile\"\n",
    "    temp_df[\"brand\"] = brand\n",
    "    df = pd.concat([df,temp_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_numbers(string):\n",
    "    string = str(string).replace(\",\",\"\")\n",
    "    if \"k\" in string:\n",
    "        if \".\" in string:\n",
    "            return int(string.replace(\"k\",\"00\").replace(\".\",\"\"))\n",
    "        else:\n",
    "            return int(string.replace(\"k\",\"00\"))\n",
    "    if \"m\" in string:\n",
    "        if \".\" in string:\n",
    "            return int(string.replace(\"m\",\"00000\").replace(\".\",\"\"))\n",
    "        else:\n",
    "            return int(string.replace(\"m\",\"000000\"))\n",
    "    return int(float(string))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only choose images\n",
    "df = df[df.media==\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.likes = df.likes.apply(handle_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.caption.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(df):\n",
    "    return df.caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text_ft = FunctionTransformer(get_text, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get page meta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv(\"brand_ig_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = meta_df.loc[:, [\"brand_ig\",\"n_posts\", \"n_followers\",\"n_following\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index=str, columns={\"brand\": \"brand_ig\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.merge(df,meta_df,how=\"left\",on=\"brand_ig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"n_posts\"] = final_df.n_posts.apply(handle_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"n_followers\"] = final_df.n_followers.apply(handle_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove posts with zero likes (to take a log transform and calculate MAPE)\n",
    "final_df = final_df[final_df.likes != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brand_meta(df):\n",
    "    return df.loc[:,[\"n_posts\", \"n_followers\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_brand_meta_ft = FunctionTransformer(get_brand_meta, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(stop_words='english', max_df=0.3, min_df=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "union = make_union(make_pipeline(get_text_ft, vect), get_brand_meta_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(final_df, final_df.likes, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_meta_dtm = union.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_meta_dtm = union.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.datasets\n",
    "import sklearn.svm\n",
    "from sklearn.metrics import r2_score\n",
    "import sklearn.feature_extraction.text\n",
    "import sklearn.utils.sparsefuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred)/ y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression = sklearn.linear_model.LinearRegression()\n",
    "regression.fit(X_train_meta_dtm, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lr = regression.predict(X_test_meta_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.697\n",
      "mape: 20.260\n"
     ]
    }
   ],
   "source": [
    "print(\"r2: %.3f\"%(r2_score(np.log(y_test),yhat_lr)))\n",
    "print(\"mape: %.3f\"%mean_absolute_percentage_error(np.log(y_test),yhat_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lasso, L1 penalized regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = sklearn.linear_model.Lasso(alpha = 0.1, max_iter=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=3000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.fit(X_train_meta_dtm,np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lasso = lasso.predict(X_test_meta_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.333\n",
      "mape: 33.447\n"
     ]
    }
   ],
   "source": [
    "print(\"r2: %.3f\"%(r2_score(np.log(y_test),yhat_lasso)))\n",
    "print(\"mape: %.3f\"%mean_absolute_percentage_error(np.log(y_test),yhat_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostRegressor(base_estimator=None, n_estimators=200, learning_rate=1, loss=\"linear\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1, loss='linear',\n",
       "         n_estimators=200, random_state=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train_meta_dtm, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_ada = ada.predict(X_test_meta_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.667\n",
      "mape: 21.684\n"
     ]
    }
   ],
   "source": [
    "print(\"r2: %.3f\"%(r2_score(np.log(y_test),yhat_ada)))\n",
    "print(\"mape: %.3f\"%mean_absolute_percentage_error(np.log(y_test),yhat_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(loss=\"ls\", learning_rate=0.1, n_estimators=100, subsample=1.0, criterion=\"friedman_mse\", min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=1, max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None, warm_start=False, presort=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=1,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(X_train_meta_dtm, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_gbr = gbr.predict(X_test_meta_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.797\n",
      "mape: 15.978\n"
     ]
    }
   ],
   "source": [
    "print(\"r2: %.3f\"%(r2_score(np.log(y_test),yhat_gbr)))\n",
    "print(\"mape: %.3f\"%mean_absolute_percentage_error(np.log(y_test),yhat_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.0e-03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97270708960411267"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore the long tail\n",
    "gbr.feature_importances_[gbr.feature_importances_ >= threshold].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_feats = gbr.feature_importances_ >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_ind = np.where(impt_feats[:-2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['777tour', 'a1', 'acer', 'acerwin10', 'available', 'bea1', 'bio',\n",
       "       'capture', 'capturedonp9', 'ces', 'ces2014', 'cute', 'debut',\n",
       "       'domore', 'dual', 'elifee6', 'experience', 'film', 'find5',\n",
       "       'flipkart', 'flyme', 'fullvision', 'g2', 'gioneee7',\n",
       "       'gioneestargima', 'guys', 'gwatchr', 'hewlettpackard', 'howiflex',\n",
       "       'hp', 'htcgoesfullfrontal', 'htcone', 'htcrihanna', 'htcu11',\n",
       "       'huaweimate10', 'huaweip10', 'huaweip8', 'ifa15', 'introducing',\n",
       "       'lenovo', 'lgg6', 'lgv30', 'lgv30sthinq', 'lounge', 'makesmiles',\n",
       "       'meizu', 'mi', 'moto360', 'motox', 'motoxmade', 'mymotox',\n",
       "       'mysuperg', 'new', 'nokia', 'nyfw', 'oneplus5t', 'oppofind5',\n",
       "       'oppon1', 'optimus', 'osnap', 'p7max', 'prefer', 'rai', 'redmi',\n",
       "       'redminote3', 's11', 'selfieexpert', 'selfieflash', 'selfiestan',\n",
       "       'share', 'shotononeplus', 'sony', 'sonycamera', 'sonynex', 'tablet',\n",
       "       'taken', 'thank', 'u11', 'v20', 'vivomobile',\n",
       "       'weekenderwithmicromax', 'xiaomipics', 'yoga', 'youtube'],\n",
       "      dtype='<U31')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vect.get_feature_names())[impt_feats[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.3, max_features=None, min_df=4,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train.caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.feature_importances_[impt_feats].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df[\"word\"] = np.array(vect.get_feature_names())[impt_feats[:-2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df[\"importance\"] = gbr.feature_importances_[impt_feats][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_df = importance_df.sort_values(by=\"importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_importance_df = pd.DataFrame([[\"n_followers\",0.24085896],[\"n_posts\",0.08033263,]],columns=[\"word\",\"importance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_followers</td>\n",
       "      <td>0.240859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_posts</td>\n",
       "      <td>0.080333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meizu</td>\n",
       "      <td>0.028165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gioneee7</td>\n",
       "      <td>0.022344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gioneestargima</td>\n",
       "      <td>0.019738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shotononeplus</td>\n",
       "      <td>0.018512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mi</td>\n",
       "      <td>0.017792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xiaomipics</td>\n",
       "      <td>0.017215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>htcgoesfullfrontal</td>\n",
       "      <td>0.017102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fullvision</td>\n",
       "      <td>0.016946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>selfiestan</td>\n",
       "      <td>0.016943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>motox</td>\n",
       "      <td>0.015383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>selfieexpert</td>\n",
       "      <td>0.015354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgg6</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>taken</td>\n",
       "      <td>0.014231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>selfieflash</td>\n",
       "      <td>0.013436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bea1</td>\n",
       "      <td>0.013253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>huaweimate10</td>\n",
       "      <td>0.012805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>htcrihanna</td>\n",
       "      <td>0.012797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>flyme</td>\n",
       "      <td>0.012461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  word  importance\n",
       "0          n_followers    0.240859\n",
       "1              n_posts    0.080333\n",
       "2                meizu    0.028165\n",
       "3             gioneee7    0.022344\n",
       "4       gioneestargima    0.019738\n",
       "5        shotononeplus    0.018512\n",
       "6                   mi    0.017792\n",
       "7           xiaomipics    0.017215\n",
       "8   htcgoesfullfrontal    0.017102\n",
       "9           fullvision    0.016946\n",
       "10          selfiestan    0.016943\n",
       "11               motox    0.015383\n",
       "12        selfieexpert    0.015354\n",
       "13                lgg6    0.014271\n",
       "14               taken    0.014231\n",
       "15         selfieflash    0.013436\n",
       "16                bea1    0.013253\n",
       "17        huaweimate10    0.012805\n",
       "18          htcrihanna    0.012797\n",
       "19               flyme    0.012461"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([meta_importance_df,importance_df],axis = 0).reset_index(drop=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only useful features and use all data in final fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(gbr, prefit=True)\n",
    "X_train_new = model.transform(X_train_meta_dtm)\n",
    "X_test_new = model.transform(X_test_meta_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = np.vstack([X_train_new.toarray(),X_test_new.toarray()])\n",
    "y_final = np.concatenate([y_train.values, y_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=1,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(X_final, np.log(y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_gbr_2 = gbr.predict(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2: 0.800\n",
      "mape: 15.765\n"
     ]
    }
   ],
   "source": [
    "print(\"r2: %.3f\"%(r2_score(np.log(y_test),yhat_gbr_2)))\n",
    "print(\"mape: %.3f\"%mean_absolute_percentage_error(np.log(y_test),yhat_gbr_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
